Without using any feature

model_BAGraph: 100,000 iteration
model_differentGraph: 100,000 iteration
FINDER: Best iteration
Model Description:
hidden_layers =  5  
replay_buffer_capacity= int(1e3)    #"Size of the replay buffer."
batch_size = 128      #"Learning"
learning_rate = 0.01   #"Learning Rate"
update_target_network = 1000 #"Update the target network"
discount_factor= 0.9  
epsilon_start=1.0
epsilon_end=0.15
epsilon_decay_duration=num_train_episodes
optimizer_str="adam"
loss_str="huber
%No Features included 
# Rewarding system: (mean of previous step lcc - mean of current step lcc)
reward = (self.alpha * decrease in gamma +(1-self.alpha)*decrease in beta)

