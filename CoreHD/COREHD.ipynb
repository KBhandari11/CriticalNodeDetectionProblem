{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1e6332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOt FROM\n",
    "#https://github.com/hcmidt/corehd/blob/master/chouffe.py\n",
    "\n",
    "## suboptimal, but fast, implementation of the corehd and weak-neighbor algorithm ##\n",
    "## The code can be implemented by hirarchical binning, eading to better time complexity ##\n",
    "\n",
    "import sys\n",
    "import networkx as nx\n",
    "from random import *\n",
    "\n",
    "def score(v,G,scm='HD'):\n",
    "    # compute the score of node v in G\n",
    "\n",
    "    if scm == 'HD':\n",
    "    # high degree score : uniform\n",
    "        scr = 0\n",
    "    elif scm == 'WN':\n",
    "    # weak-neighbor1 score\n",
    "        scr = sum( (G.degree(nb) for nb in G[v]) )\n",
    "        scr = - scr\n",
    "    elif scm == 'SN':\n",
    "    # weak-neighbor2 score\n",
    "        if G.degree(v) != 0:\n",
    "            scr = sum( (G.degree(nb) for nb in G[v]) )\n",
    "            scr = G.degree(v) - scr/float(G.degree(v))\n",
    "        else:\n",
    "            scr = 0\n",
    "    else:\n",
    "        sys.exit(\"Error : score function is not defined.\")\n",
    "\n",
    "    return scr\n",
    "\n",
    "def category(v,k,G,scm='HD'):\n",
    "    # computes the right category to order node to\n",
    "    if scm == 'HD':\n",
    "        dgr = max(k-1,G.degree(v))\n",
    "    elif scm == 'WN':\n",
    "        dgr = max(k-1,G.degree(v))\n",
    "    elif scm == 'SN':\n",
    "        if G.degree(v) < k:\n",
    "            dgr = k-1\n",
    "        else:\n",
    "            dgr = k\n",
    "    else:\n",
    "        sys.exit(\"Error : algorithm is not defined.\")\n",
    "\n",
    "    return dgr\n",
    "\n",
    "def max_cat(k,G,scm='HD'):\n",
    "    # computes the max category in dict\n",
    "    if scm == 'HD':\n",
    "        out = max(dict(G.degree()).values())\n",
    "    elif scm == 'WN':\n",
    "        out = max(G.degree().values())\n",
    "    elif scm == 'SN':\n",
    "        out = k\n",
    "    else:\n",
    "        sys.exit(\"Error : algorithm is not defined. Cannot obtain max.\")\n",
    "\n",
    "    return out\n",
    "\n",
    "def preprocess(k,G,scm='HD'):\n",
    "    # suboptimal, but O(|G|), computation of some initial properties\n",
    "\n",
    "    # size of initial graph\n",
    "    N0 = len(G)\n",
    "    # compute the k-core in O(|G|) steps (not really necessary)\n",
    "    G = nx.k_core(G,k)\n",
    "    # size of the initial k-core\n",
    "    N = len(G)\n",
    "\n",
    "    # if the core is empty we are done\n",
    "    if N == 0:\n",
    "        return G, 0, dict(), dict(), dict(), N0, N\n",
    "\n",
    "    dmax = max_cat(k,G,scm)\n",
    "\n",
    "    # Initialize the dictionary, H, with \n",
    "    # H[degree][score] = {i_1: 1, ..., i_r:1} and i_j indicating a node\n",
    "    # degree = k-1,...,d because it is not necessary to distinguish nodes of degree smaller k.\n",
    "    # the k-1 nodes need not be organized by score, but it makes the code less prune to errors and doesn't cost us much\n",
    "    H = { d: dict() for d in range(k-1,dmax+1) }\n",
    "\n",
    "    # collect the score for every node \n",
    "    score_dict = {}\n",
    "    # collect the max score for each 'degree' = k-1\n",
    "    max_score_dict = {}\n",
    "\n",
    "    for v in G.nodes():\n",
    "        dgr = category(v,k,G,scm)\n",
    "        scr = score(v,G,scm)\n",
    "        score_dict[v] = scr\n",
    "        # sort them in dictionaries by scores.\n",
    "        try:\n",
    "            H[dgr][scr][v] = 1\n",
    "        except KeyError:\n",
    "            # create if it does not already exist\n",
    "            H[dgr][scr] = dict()\n",
    "            H[dgr][scr][v] = 1\n",
    "\n",
    "    # track currently largest score for each H[.] \n",
    "    for sub_dict_name in H.keys():\n",
    "        try:\n",
    "            mx_scr = max(H[sub_dict_name].keys())\n",
    "        except ValueError:\n",
    "            mx_scr = None \n",
    "\n",
    "        max_score_dict[sub_dict_name] = mx_scr\n",
    "\n",
    "\n",
    "    return G, dmax, H, max_score_dict, score_dict, N0, N\n",
    "\n",
    "#### JUST ADAPT d \\in {<k or >k} for SN\n",
    "def destroy(k,G,scm='HD'):\n",
    "    # implementation of the generalized corehd algorithm (scm='HD')\n",
    "    # and one version of the weak-neighbor algorithm (scm='WN')\n",
    "    # we assume that G has no self-loops.\n",
    "\n",
    "    ### initialize \n",
    "    # pre-processing\n",
    "    G, dmax, H, max_score_dict, score_dict, N0, N = preprocess(k,G,scm)\n",
    "    # set of seeds\n",
    "    D = []\n",
    "    if N == 0:\n",
    "        return D\n",
    "    # current indicator for either removal (d=dmax) or trimming (d=k-1)\n",
    "    if max_score_dict[k-1] == None:\n",
    "        d = dmax\n",
    "    else:\n",
    "        d = k-1\n",
    "    removed_node = []\n",
    "    ### remove and trimm until the k-core is empty\n",
    "    cnt = 0 ; done = False ;\n",
    "    while cnt < N and done == False: \n",
    "        cnt += 1\n",
    "\n",
    "        ## remove node \n",
    "\n",
    "        # get the max score of degree d nodes\n",
    "        mx_scr_d = max_score_dict[d]\n",
    "\n",
    "        # remove one of them at random\n",
    "        v = choice(list(H[d][mx_scr_d].keys()))\n",
    "\n",
    "        # if d > k-1 add them to the seed set\n",
    "        if d >= k:\n",
    "            D.append(v)\n",
    "\n",
    "        # remove element from H and set its score to None\n",
    "        del H[d][mx_scr_d][v]\n",
    "        score_dict[v] = None\n",
    "\n",
    "        # check for newest largest score\n",
    "        if H[d][mx_scr_d] == {}:\n",
    "            del H[d][mx_scr_d]\n",
    "        # update max_score_dict\n",
    "        # suboptimal\n",
    "        try:\n",
    "            max_score_dict[d] = max(H[d].keys())\n",
    "        except ValueError:\n",
    "            max_score_dict[d] = None\n",
    "\n",
    "        ## update the neighbors \n",
    "        dv = G[v]\n",
    "        ddv = set()\n",
    "        # remove neighbors from dict (for now)\n",
    "        # other cases we will take care of below. E.g. updating max_score of the new degree\n",
    "        for nb in dv:\n",
    "            remove_node_by_score(nb,G,H,max_score_dict,score_dict,k,scm)\n",
    "            ddv = ddv | set(G[nb].keys())\n",
    "\n",
    "        # remove also neighbors neighbors (except v) because their score will change\n",
    "        ddv = ddv - set([v])\n",
    "        ddv = ddv - set(dv)\n",
    "        for nnb in ddv:\n",
    "            remove_node_by_score(nnb,G,H,max_score_dict,score_dict,k,scm)\n",
    "        removed_node.append(v)\n",
    "        ## remove v from G\n",
    "        G.remove_node(v)\n",
    "\n",
    "        # update the degrees of the neighbors and their scores\n",
    "        for nb in dv:\n",
    "            add_node_by_score(nb,G,H,max_score_dict,score_dict,k,scm)\n",
    "        # update scores of the neighbors neighbors\n",
    "        for nnb in ddv:\n",
    "            add_node_by_score(nnb,G,H,max_score_dict,score_dict,k,scm)\n",
    "\n",
    "        ## check if dmax needs updating and do so if necessary. not necessary\n",
    "        if max_score_dict[d] == None:\n",
    "            # attempt to update\n",
    "            try: \n",
    "                while max_score_dict[dmax] == None:\n",
    "                    dmax -= 1\n",
    "            # unless there are no nodes left\n",
    "            except KeyError:\n",
    "                done = True\n",
    "                #sys.exit('Error!')\n",
    "\n",
    "        ## update d\n",
    "        if max_score_dict[k-1] != None:\n",
    "            d = k-1\n",
    "        else:\n",
    "            d = dmax\n",
    "    return D, N, removed_node \n",
    "\n",
    "\n",
    "def add_node_by_score(v,G,H,max_score_dict,score_dict,k,scm):\n",
    "    # get new score\n",
    "    score_dict[v] = score(v,G,scm)\n",
    "    # get new category (degree) for dict reordering\n",
    "    dgr = category(v,k,G,scm)\n",
    "    # insert into proper spot\n",
    "    try:\n",
    "        H[dgr][score_dict[v]][v] = 1\n",
    "    except KeyError:\n",
    "        # create if it does not already exist\n",
    "        H[dgr][score_dict[v]] = dict()\n",
    "        H[dgr][score_dict[v]][v] = 1\n",
    "    # update max_score\n",
    "    if max_score_dict[dgr] == None or max_score_dict[dgr] < score_dict[v]:\n",
    "        max_score_dict[dgr] = score_dict[v]\n",
    "\n",
    "def remove_node_by_score(v,G,H,max_score_dict,score_dict,k,scm):\n",
    "    # find the right dict\n",
    "    dgr = category(v,k,G,scm)\n",
    "    # remove the current nb\n",
    "    del H[dgr][score_dict[v]][v]\n",
    "    # if there are no more nodes of this particular score, remove the dict\n",
    "    if H[dgr][score_dict[v]] == {}:\n",
    "        del H[dgr][score_dict[v]]\n",
    "    # if the score was equal to the max score, update max_score_dict\n",
    "    if score_dict[v] == max_score_dict[dgr]:\n",
    "        try:\n",
    "            max_score_dict[dgr] = max(H[dgr].keys())\n",
    "        # no more nodes left of degree d\n",
    "        except ValueError:\n",
    "            max_score_dict[dgr] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3f0886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_to_file(filepath,file_list,k=3):\n",
    "    for name in file_list:\n",
    "        file = filepath+name+\".txt\"\n",
    "        fh = open(file, \"rb\")\n",
    "        GRAPH = nx.read_edgelist(fh)\n",
    "        fh.close()\n",
    "        nodes = GRAPH.nodes()\n",
    "        GRAPH.remove_edges_from(nx.selfloop_edges(GRAPH))\n",
    "        print(name)\n",
    "        map = {n:int(i) for i, n in enumerate(nodes)}\n",
    "        GRAPH = nx.relabel_nodes(GRAPH, map)\n",
    "        D,N,removed_nodes = destroy(k,GRAPH)\n",
    "        # open file in write mode\n",
    "        with open(r'./'+name+'.txt', 'w') as fp:\n",
    "            for item in removed_nodes:\n",
    "                # write each item on a new line\n",
    "                fp.write(\"%s\\n\" % item)\n",
    "        print('Done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e52e83eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testTrain\n",
      "Done\n",
      "corruption\n",
      "Done\n",
      "bio-grid-human\n",
      "Done\n",
      "foodweb-baywet\n",
      "Done\n",
      "inf-USAir97\n",
      "Done\n",
      "moreno_crime_projected\n",
      "Done\n",
      "opsahl-openflights\n",
      "Done\n",
      "household\n",
      "Done\n",
      "faa\n",
      "Done\n",
      "facebook\n",
      "Done\n",
      "powergrid\n",
      "Done\n",
      "netscience\n",
      "Done\n",
      "HI-II-14\n",
      "Done\n",
      "Digg\n",
      "Done\n",
      "GeneInteraction\n",
      "Done\n",
      "ReliableInteraction\n",
      "Done\n",
      "ba_300_20_house_1\n",
      "Done\n",
      "ba_300_40_house_2\n",
      "Done\n",
      "ba_300_60_house_3\n",
      "Done\n",
      "ba_300_80_house_4\n",
      "Done\n",
      "ba_300_100_house_5\n",
      "Done\n",
      "ba_300_20_grid_1\n",
      "Done\n",
      "ba_300_40_grid_2\n",
      "Done\n",
      "ba_300_60_grid_3\n",
      "Done\n",
      "ba_300_80_grid_4\n",
      "Done\n",
      "ba_300_100_grid_5\n",
      "Done\n",
      "tree_8_20_cycle_1\n",
      "Done\n",
      "tree_8_40_cycle_2\n",
      "Done\n",
      "tree_8_60_cycle_3\n",
      "Done\n",
      "tree_8_80_cycle_4\n",
      "Done\n",
      "tree_8_100_cycle_5\n",
      "Done\n",
      "tree_8_20_grid_1\n",
      "Done\n",
      "tree_8_40_grid_2\n",
      "Done\n",
      "tree_8_60_grid_3\n",
      "Done\n",
      "tree_8_80_grid_4\n",
      "Done\n",
      "tree_8_100_grid_5\n",
      "Done\n",
      "ba_60_10_house_1\n",
      "Done\n",
      "ba_60_20_house_2\n",
      "Done\n",
      "ba_60_30_house_3\n",
      "Done\n",
      "ba_60_10_fan_1\n",
      "Done\n",
      "ba_60_20_fan_2\n",
      "Done\n",
      "ba_60_30_fan_3\n",
      "Done\n",
      "ba_60_10_clique_1\n",
      "Done\n",
      "ba_60_20_clique_2\n",
      "Done\n",
      "ba_60_30_clique_3\n",
      "Done\n",
      "ba_60_10_diamond_1\n",
      "Done\n",
      "ba_60_20_diamond_2\n",
      "Done\n",
      "ba_60_30_diamond_3\n",
      "Done\n",
      "ba_60_10_star_1\n",
      "Done\n",
      "ba_60_20_star_2\n",
      "Done\n",
      "ba_60_30_star_3\n",
      "Done\n",
      "ba_60_10_grid_1\n",
      "Done\n",
      "ba_60_20_grid_2\n",
      "Done\n",
      "ba_60_30_grid_3\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "filepath = \"../real/\"\n",
    "file_list =  [\"testTrain\",\"corruption\",\"bio-grid-human\",\"foodweb-baywet\",\"inf-USAir97\",\"moreno_crime_projected\",'opsahl-openflights','household','faa','facebook','powergrid','netscience','HI-II-14','Digg','GeneInteraction','ReliableInteraction']\n",
    "save_to_file(filepath,file_list,k=2)\n",
    "file_list = ['ba_300_20_house_1', 'ba_300_40_house_2', 'ba_300_60_house_3', 'ba_300_80_house_4', 'ba_300_100_house_5', 'ba_300_20_grid_1', 'ba_300_40_grid_2', 'ba_300_60_grid_3', 'ba_300_80_grid_4', 'ba_300_100_grid_5']\n",
    "filepath = \"../Cross_Validation/GNNexplanation/\"\n",
    "save_to_file(filepath,file_list,k=2)\n",
    "file_list = [ 'tree_8_20_cycle_1', 'tree_8_40_cycle_2', 'tree_8_60_cycle_3', 'tree_8_80_cycle_4', 'tree_8_100_cycle_5', 'tree_8_20_grid_1', 'tree_8_40_grid_2', 'tree_8_60_grid_3', 'tree_8_80_grid_4', 'tree_8_100_grid_5']\n",
    "filepath = \"../Cross_Validation/GNNexplanation/\"\n",
    "save_to_file(filepath,file_list,k=2)\n",
    "file_list =['ba_60_10_house_1', 'ba_60_20_house_2', 'ba_60_30_house_3', 'ba_60_10_fan_1', 'ba_60_20_fan_2', 'ba_60_30_fan_3', 'ba_60_10_clique_1', 'ba_60_20_clique_2', 'ba_60_30_clique_3', 'ba_60_10_diamond_1', 'ba_60_20_diamond_2', 'ba_60_30_diamond_3', 'ba_60_10_star_1', 'ba_60_20_star_2', 'ba_60_30_star_3', 'ba_60_10_grid_1', 'ba_60_20_grid_2', 'ba_60_30_grid_3']\n",
    "filepath = \"../Cross_Validation/GNNexplanation/New/\"\n",
    "save_to_file(filepath,file_list,k=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
