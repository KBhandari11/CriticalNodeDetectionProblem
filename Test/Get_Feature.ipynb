{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bbf2de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import networkx as nx\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.sparse.linalg import eigsh\n",
    "import json\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "def gen_graph(cur_n, g_type,seed=None):\n",
    "    random.seed(seed)\n",
    "    if g_type == 'erdos_renyi':\n",
    "        #print(random.uniform(0.15,0.20))\n",
    "        g = nx.erdos_renyi_graph(n=cur_n, p=random.uniform(0.15,0.20),seed = seed)\n",
    "    elif g_type == 'powerlaw':\n",
    "        g = nx.powerlaw_cluster_graph(n=cur_n, m=random.randint(2,4), p=random.uniform(0.1,0.5),seed = seed)\n",
    "    elif g_type == 'small-world':\n",
    "        #print(random.randint(2,5),random.uniform(0.1,0.2))\n",
    "        g = nx.newman_watts_strogatz_graph(n=cur_n, k=random.randint(2,5), p=random.uniform(0.1,0.2),seed = seed)\n",
    "    elif g_type == 'barabasi_albert':\n",
    "        #print(random.randint(2,5))\n",
    "        g = nx.barabasi_albert_graph(n=cur_n, m=random.randint(2,5),seed = seed)\n",
    "    elif g_type == 'geometric':\n",
    "        g = nx.random_geometric_graph(cur_n, random.uniform(0.1,0.4),seed = seed)\n",
    "    return g\n",
    "    \n",
    "def get_from_json(file_path):\n",
    "    with open(file_path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data\n",
    "def gen_new_graphs(graph_type,seed = None):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    a = np.random.choice(graph_type) if len(graph_type) !=1 else graph_type[0]\n",
    "    number_nodes = 30\n",
    "    graph = gen_graph(number_nodes, a,seed)\n",
    "    #graph =add_super_node(graph)\n",
    "    active = 1\n",
    "    nx.set_node_attributes(graph,active, \"active\")\n",
    "    return graph   \n",
    "def input_graph(graph_path,file):\n",
    "    fh = open(graph_path+str(file), \"rb\")\n",
    "    GRAPH = nx.read_edgelist(fh)\n",
    "    fh.close()\n",
    "    nodes = GRAPH.nodes()\n",
    "    map = {n:int(i) for i, n in enumerate(nodes)}\n",
    "    GRAPH = nx.relabel_nodes(GRAPH, map)\n",
    "    GRAPH.remove_edges_from(nx.selfloop_edges(GRAPH))\n",
    "    return GRAPH, map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "575b6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def molloy_reed(g):\n",
    "  all_degree =   np.array(g.degree())[:,1]\n",
    "  degs = np.delete(all_degree,-1)\n",
    "  k = degs.mean()\n",
    "  k2 = np.mean(degs ** 2)\n",
    "  beta = k2/k\n",
    "  return beta\n",
    "def global_feature(g): \n",
    "    feature = {}\n",
    "    M = len(g.edges())\n",
    "    N = len(g)\n",
    "    degs =   np.array(g.degree())[:,1]\n",
    "    min_k = np.min(degs)\n",
    "    \n",
    "    k1 = degs.mean()\n",
    "    k2 = np.mean(degs** 2)\n",
    "    div = k2 - k1**2\n",
    "    A = nx.to_scipy_sparse_array(g, weight='weight',dtype=float,format='csr')\n",
    "    adj_lams = np.sort(eigsh(A, k=N-1, which='LA', return_eigenvectors=False))\n",
    "    feature[\"nodes\"] = N\n",
    "    feature[\"edges\"] = M\n",
    "    feature[\"heterogeneity\"] = div/k1\n",
    "    feature[\"density\"] = (2*M)/(N*(N-1))\n",
    "    feature[\"resilience\"] = molloy_reed(g)\n",
    "    #power_law_exponent = 1 + N / sum(np.log(degs/min_k))\n",
    "    feature[\"modularity\"] = nx_comm.modularity(g,nx_comm.label_propagation_communities(g))\n",
    "    try:\n",
    "        varepsilons = nx.algorithms.distance_measures.eccentricity(g).values()\n",
    "        feature[\"eccentricity\"]=  np.mean(list(varepsilons))\n",
    "        feature[\"diameter\"] = nx.algorithms.distance_measures.diameter(g)\n",
    "        feature[\"radius\"] = nx.algorithms.distance_measures.radius(g)\n",
    "    except:\n",
    "        lcc = max(nx.connected_components(g), key=len)\n",
    "        subGraph = g.subgraph(lcc)\n",
    "        varepsilons = nx.algorithms.distance_measures.eccentricity(subGraph).values()\n",
    "        feature[\"eccentricity\"]=  np.mean(list(varepsilons))\n",
    "        feature[\"diameter\"] = nx.algorithms.distance_measures.diameter(subGraph)\n",
    "        feature[\"radius\"] = nx.algorithms.distance_measures.radius(subGraph)\n",
    "    feature[\"spectral_radius\"]=adj_lams[-1]\n",
    "    feature[\"spectral_gap\"]=  adj_lams[-1]-adj_lams[-2]\n",
    "    feature[\"natural_connectivity\"]= np.log2(sum(np.exp(np.real(adj_lams)))/len(adj_lams))\n",
    "    feature[\"global_efficiency\"] = nx.algorithms.efficiency_measures.global_efficiency(g)\n",
    "    feature[\"assortativity\"] = nx.algorithms.assortativity.degree_assortativity_coefficient(g)\n",
    "    #global_properties =np.hstack((nodes, edges,density,resilience,heterogeneity,power_law_exponent, modularity,eccentricity,diameter,radius,spectral_radius,spectral_gap,natural_connectivity,assortativity))\n",
    "    return feature\n",
    "feature = get_from_json(\"../Dataset/features.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3789d444",
   "metadata": {},
   "source": [
    "# Synthetic Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2118e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path= [\"../Dataset/SyntheticGraph/Degree/\",\"../Dataset/SyntheticGraph/Homogeneity/\"]\n",
    "for path in graph_path:\n",
    "    file_list = [f for f in listdir(path) if isfile(join(path, f))] \n",
    "    for i, graph_name in enumerate(file_list):\n",
    "        GRAPH, _ = input_graph(path,graph_name)\n",
    "        feature[graph_name] =  global_feature(GRAPH)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936cfc38",
   "metadata": {},
   "source": [
    "# BA with Motifs Attached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ce35f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = \"../Dataset/Validation/Motifs_Attached/BA/\"\n",
    "file_list = [f for f in listdir(graph_path) if isfile(join(graph_path, f))] \n",
    "for i, graph_name in enumerate(file_list):\n",
    "    GRAPH, _ = input_graph(graph_path,graph_name)\n",
    "    feature[graph_name] =  global_feature(GRAPH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af260ea4",
   "metadata": {},
   "source": [
    "# Tree with Motifs Attached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1e432c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path =\"../Dataset/Validation/Motifs_Attached/Tree/\" \n",
    "file_list = [f for f in listdir(graph_path) if isfile(join(graph_path, f))] \n",
    "for i, graph_name in enumerate(file_list):\n",
    "    GRAPH, _ = input_graph(graph_path,graph_name)\n",
    "    feature[graph_name] =  global_feature(GRAPH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c929af",
   "metadata": {},
   "source": [
    "# Real World Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14e8d97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corruption.txt ,foodweb-baywet.txt ,inf-USAir97.txt ,moreno_crime_projected.txt ,opsahl-openflights.txt ,household.txt ,faa.txt ,facebook.txt ,powergrid.txt ,netscience.txt ,"
     ]
    }
   ],
   "source": [
    "graph_path =  \"../Dataset/Real/\"\n",
    "file_list = [\"corruption.txt\",\"foodweb-baywet.txt\",\"inf-USAir97.txt\",\"moreno_crime_projected.txt\",'opsahl-openflights.txt','household.txt','faa.txt','facebook.txt','powergrid.txt','netscience.txt']#[f.split(\".\")[0] for f in listdir(graph_path) if isfile(join(graph_path, f))] \n",
    "for i, graph_name in enumerate(file_list):\n",
    "    print(graph_name, end=\" ,\")\n",
    "    GRAPH, _ = input_graph(graph_path,graph_name)\n",
    "    feature[graph_name] =  global_feature(GRAPH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4d240c",
   "metadata": {},
   "source": [
    "# Cancer Gene Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1d62a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = \"../Dataset/GeneNetwork/\"\n",
    "file_list = [f for f in listdir(graph_path) if isfile(join(graph_path, f))] \n",
    "for i, graph_name in enumerate(file_list):\n",
    "    GRAPH, _ = input_graph(graph_path,graph_name)\n",
    "    feature[graph_name] =  global_feature(GRAPH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb9886",
   "metadata": {},
   "source": [
    "# Dump to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c8e9a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../Dataset/features.json\", \"w\") as outfile:\n",
    "    json.dump(feature, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
