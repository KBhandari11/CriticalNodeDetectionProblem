{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAPH WORLD: SBM Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import collections\n",
    "import enum\n",
    "import math\n",
    "import random\n",
    "from typing import Dict, Sequence, List, Tuple\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from graph_tool.all import *\n",
    "import dataclasses\n",
    "import numpy as np\n",
    "\n",
    "class MatchType(enum.Enum):\n",
    "  \"\"\"Indicates type of feature/graph membership matching to do.\n",
    "    RANDOM: feature memberships are generated randomly.\n",
    "    NESTED: for # feature groups >= # graph groups. Each feature cluster is a\n",
    "      sub-cluster of a graph cluster. Multiplicity of sub-clusters per\n",
    "      graph cluster is kept as uniform as possible.\n",
    "    GROUPED: for # feature groups <= # graph groups. Each graph cluster is a\n",
    "      sub-cluster of a feature cluster. Multiplicity of sub-clusters per\n",
    "      feature cluster is kept as uniform as possible.\n",
    "  \"\"\"\n",
    "  RANDOM = 1\n",
    "  NESTED = 2\n",
    "  GROUPED = 3\n",
    "@dataclasses.dataclass\n",
    "class StochasticBlockModel:\n",
    "  \"\"\"Stores data for stochastic block model graphs with features.\n",
    "  Attributes:\n",
    "    graph: graph-tool Graph object.\n",
    "    graph_memberships: list of integer node classes.\n",
    "    node_features: numpy array of node features.\n",
    "    feature_memberships: list of integer node feature classes.\n",
    "    edge_features: map from edge tuple to numpy array. Only stores undirected\n",
    "      edges, i.e. (0, 1) will be in the map, but (1, 0) will not be.\n",
    "  \"\"\"\n",
    "  graph: graph_tool.Graph = Ellipsis\n",
    "  graph_memberships: np.ndarray = Ellipsis\n",
    "  node_features: np.ndarray = Ellipsis\n",
    "  feature_memberships: np.ndarray = Ellipsis\n",
    "  edge_features: Dict[Tuple[int, int], np.ndarray] = Ellipsis\n",
    "\n",
    "\n",
    "def _GetNestingMap(large_k, small_k):\n",
    "  \"\"\"Given two group sizes, computes a \"nesting map\" between groups.\n",
    "  This function will produce a bipartite map between two sets of \"group nodes\"\n",
    "  that will be used downstream to partition nodes in a bigger graph. The map\n",
    "  encodes which groups from the larger set are nested in certain groups from\n",
    "  the smaller set.\n",
    "  As currently implemented, nesting is assigned as evenly as possible. If\n",
    "  large_k is an integer multiple of small_k, each smaller-set group will be\n",
    "  mapped to exactly (large_k/small_k) larger-set groups. If there is a\n",
    "  remainder r, the first r smaller-set groups will each have one extra nested\n",
    "  larger-set group.\n",
    "  Args:\n",
    "    large_k: (int) size of the larger group set\n",
    "    small_k: (int) size of the smaller group set\n",
    "  Returns:\n",
    "    nesting_map: (dict) map from larger group set indices to lists of\n",
    "      smaller group set indices\n",
    "  \"\"\"\n",
    "  min_multiplicity = int(math.floor(large_k / small_k))\n",
    "  max_bloated_group_index = large_k - small_k * min_multiplicity - 1\n",
    "  nesting_map = collections.defaultdict(list)\n",
    "  pos = 0\n",
    "  for i in range(small_k):\n",
    "    for _ in range(min_multiplicity + int(i <= max_bloated_group_index)):\n",
    "      nesting_map[i].append(pos)\n",
    "      pos += 1\n",
    "  return nesting_map\n",
    "\n",
    "\n",
    "def _GenerateFeatureMemberships(\n",
    "    graph_memberships,\n",
    "    num_groups=None,\n",
    "    match_type=MatchType.RANDOM):\n",
    "  \"\"\"Generates a feature membership assignment.\n",
    "  Args:\n",
    "    graph_memberships: (list) the integer memberships for the graph SBM\n",
    "    num_groups: (int) number of groups. If None, defaults to number of unique\n",
    "      values in graph_memberships.\n",
    "    match_type: (MatchType) see the enum class description.\n",
    "  Returns:\n",
    "    memberships: a int list - index i contains feature group of node i.\n",
    "  \"\"\"\n",
    "  # Parameter checks\n",
    "  if num_groups is not None and num_groups == 0:\n",
    "    raise ValueError(\"argument num_groups must be None or positive\")\n",
    "  graph_num_groups = len(set(graph_memberships))\n",
    "  if num_groups is None:\n",
    "    num_groups = graph_num_groups\n",
    "\n",
    "  # Compute memberships\n",
    "  memberships = []\n",
    "  if match_type == MatchType.GROUPED:\n",
    "    if num_groups > graph_num_groups:\n",
    "      raise ValueError(\n",
    "        \"for match type GROUPED, must have num_groups <= graph_num_groups\")\n",
    "    nesting_map = _GetNestingMap(graph_num_groups, num_groups)\n",
    "    # Creates deterministic map from (smaller) graph clusters to (larger)\n",
    "    # feature clusters.\n",
    "    reverse_nesting_map = {}\n",
    "    for feature_cluster, graph_cluster_list in nesting_map.items():\n",
    "      for cluster in graph_cluster_list:\n",
    "        reverse_nesting_map[cluster] = feature_cluster\n",
    "    for cluster in graph_memberships:\n",
    "      memberships.append(reverse_nesting_map[cluster])\n",
    "  elif match_type == MatchType.NESTED:\n",
    "    if num_groups < graph_num_groups:\n",
    "      raise ValueError(\n",
    "        \"for match type NESTED, must have num_groups >= graph_num_groups\")\n",
    "    nesting_map = _GetNestingMap(num_groups, graph_num_groups)\n",
    "    # Creates deterministic map from (smaller) feature clusters to (larger)\n",
    "    # graph clusters.\n",
    "    for graph_cluster_id, feature_cluster_ids in nesting_map.items():\n",
    "      sorted_feature_cluster_ids = sorted(feature_cluster_ids)\n",
    "      num_feature_groups = len(sorted_feature_cluster_ids)\n",
    "      feature_pi = np.ones(num_feature_groups) / num_feature_groups\n",
    "      num_graph_cluster_nodes = np.sum(\n",
    "        [i == graph_cluster_id for i in graph_memberships])\n",
    "      sub_memberships = _GenerateNodeMemberships(num_graph_cluster_nodes,\n",
    "                                                 feature_pi)\n",
    "      sub_memberships = [sorted_feature_cluster_ids[i] for i in sub_memberships]\n",
    "      memberships.extend(sub_memberships)\n",
    "  else:  # MatchType.RANDOM\n",
    "    memberships = random.choices(range(num_groups), k=len(graph_memberships))\n",
    "  return np.array(sorted(memberships))\n",
    "\n",
    "\n",
    "def _ComputeExpectedEdgeCounts(num_edges, num_vertices,\n",
    "                               pi,\n",
    "                               prop_mat):\n",
    "  \"\"\"Computes expected edge counts within and between communities.\n",
    "  Args:\n",
    "    num_edges: expected number of edges in the graph.\n",
    "    num_vertices: number of nodes in the graph\n",
    "    pi: interable of non-zero community size proportions. Must sum to 1.0, but\n",
    "      this check is left to the caller of this internal function.\n",
    "    prop_mat: square, symmetric matrix of community edge count rates. Entries\n",
    "      must be non-negative, but this check is left to the caller.\n",
    "  Returns:\n",
    "    symmetric matrix with shape prop_mat.shape giving expected edge counts.\n",
    "  \"\"\"\n",
    "  scale = np.matmul(pi, np.matmul(prop_mat, pi)) * num_vertices ** 2\n",
    "  prob_mat = prop_mat * num_edges / scale\n",
    "  return np.outer(pi, pi) * prob_mat * num_vertices ** 2\n",
    "\n",
    "\n",
    "def _ComputeCommunitySizes(num_vertices, pi):\n",
    "  \"\"\"Helper function of GenerateNodeMemberships to compute group sizes.\n",
    "  Args:\n",
    "    num_vertices: number of nodes in graph.\n",
    "    pi: interable of non-zero community size proportions.\n",
    "  Returns:\n",
    "    community_sizes: np vector of group sizes. If num_vertices * pi[i] is a\n",
    "      whole number (up to machine precision), community_sizes[i] will be that\n",
    "      number. Otherwise, this function accounts for rounding errors by making\n",
    "      group sizes as balanced as possible (i.e. increasing smallest groups by\n",
    "      1 or decreasing largest groups by 1 if needed).\n",
    "  \"\"\"\n",
    "  community_sizes = [int(x * num_vertices) for x in pi]\n",
    "  if sum(community_sizes) != num_vertices:\n",
    "    size_order = np.argsort(community_sizes)\n",
    "    delta = sum(community_sizes) - num_vertices\n",
    "    adjustment = np.sign(delta)\n",
    "    if adjustment == 1:\n",
    "      size_order = np.flip(size_order)\n",
    "    for i in range(int(abs(delta))):\n",
    "      community_sizes[size_order[i]] -= adjustment\n",
    "  return community_sizes\n",
    "\n",
    "\n",
    "def _GenerateNodeMemberships(num_vertices, pi):\n",
    "  \"\"\"Gets node memberships for sbm.\n",
    "  Args:\n",
    "    num_vertices: number of nodes in graph.\n",
    "    pi: interable of non-zero community size proportions. Must sum to 1.0, but\n",
    "      this check is left to the caller of this internal function.\n",
    "  Returns:\n",
    "    np vector of ints representing community indices.\n",
    "  \"\"\"\n",
    "  community_sizes = _ComputeCommunitySizes(num_vertices, pi)\n",
    "  memberships = np.zeros(num_vertices, dtype=int)\n",
    "  node = 0\n",
    "  for i in range(len(pi)):\n",
    "    memberships[range(node, node + community_sizes[i])] = i\n",
    "    node += community_sizes[i]\n",
    "  return memberships\n",
    "\n",
    "\n",
    "def SimulateSbm(sbm_data,\n",
    "                num_vertices,\n",
    "                num_edges,\n",
    "                pi,\n",
    "                prop_mat,\n",
    "                out_degs=None):\n",
    "  \"\"\"Generates a stochastic block model, storing data in sbm_data.graph.\n",
    "  This function uses networkx.generate_sbm. Refer to that\n",
    "  documentation for more information on the model and parameters.\n",
    "  Args:\n",
    "    sbm_data: StochasticBlockModel dataclass to store result data.\n",
    "    num_vertices: (int) number of nodes in the graph.\n",
    "    num_edges: (int) expected number of edges in the graph.\n",
    "    pi: iterable of non-zero community size proportions. Must sum to 1.0.\n",
    "    prop_mat: square, symmetric matrix of community edge count rates.\n",
    "    out_degs: Out-degree propensity for each node. If not provided, a constant\n",
    "      value will be used. Note that the values will be normalized inside each\n",
    "      group, if they are not already so.\n",
    "  Returns: (none)\n",
    "  \"\"\"\n",
    "  if round(abs(np.sum(pi) - 1.0), 12) != 0:\n",
    "    raise ValueError(\"entries of pi ( must sum to 1.0\")\n",
    "  if prop_mat.shape[0] != len(pi) or prop_mat.shape[1] != len(pi):\n",
    "    raise ValueError(\"prop_mat must be k x k where k = len(pi)\")\n",
    "  sbm_data.graph_memberships = _GenerateNodeMemberships(num_vertices, pi)\n",
    "  edge_counts = _ComputeExpectedEdgeCounts(num_edges, num_vertices, pi, prop_mat)\n",
    "  sbm_data.graph = graph_tool.generation.generate_sbm(sbm_data.graph_memberships, edge_counts, out_degs)\n",
    "  graph_tool.generation.remove_self_loops(sbm_data.graph)\n",
    "  graph_tool.generation.remove_parallel_edges(sbm_data.graph)\n",
    "  sbm_data.graph.reindex_edges()\n",
    "\n",
    "\n",
    "def SimulateFeatures(sbm_data,\n",
    "                     center_var,\n",
    "                     feature_dim,\n",
    "                     num_groups,\n",
    "                     match_type=MatchType.RANDOM,\n",
    "                     cluster_var=1.0,\n",
    "                     normalize_features=True):\n",
    "  \"\"\"Generates node features using multivate normal mixture model.\n",
    "  This function does nothing and throws a warning if\n",
    "  sbm_data.graph_memberships is empty. Run SimulateSbm to fill that field.\n",
    "  Feature data is stored as an attribute of sbm_data named 'node_features'.\n",
    "  Args:\n",
    "    sbm_data: StochasticBlockModel dataclass to store result data.\n",
    "    center_var: (float) variance of feature cluster centers. When this is 0.0,\n",
    "      the signal-to-noise ratio is 0.0. When equal to cluster_var, SNR is 1.0.\n",
    "    feature_dim: (int) dimension of the multivariate normal.\n",
    "   num_groups: (int) number of centers. Generated by a multivariate normal with\n",
    "     mean zero and covariance matrix cluster_var * I_{feature_dim}.\n",
    "    match_type: (MatchType) see sbm_simulator.MatchType for details.\n",
    "    cluster_var: (float) variance of feature clusters around their centers.\n",
    "  Raises:\n",
    "    RuntimeWarning: if simulator has no graph or a graph with no nodes.\n",
    "  \"\"\"\n",
    "  if sbm_data.graph_memberships is None:\n",
    "    raise RuntimeWarning(\"No graph_memberships found: no features generated. \"\n",
    "                         \"Run SimulateSbm to generate graph_memberships.\")\n",
    "\n",
    "  # Get memberships\n",
    "  sbm_data.feature_memberships = _GenerateFeatureMemberships(\n",
    "    graph_memberships=sbm_data.graph_memberships,\n",
    "    num_groups=num_groups,\n",
    "    match_type=match_type)\n",
    "\n",
    "  # Get centers\n",
    "  centers = []\n",
    "  center_cov = np.identity(feature_dim) * center_var\n",
    "  cluster_cov = np.identity(feature_dim) * cluster_var\n",
    "  for _ in range(num_groups):\n",
    "    center = np.random.multivariate_normal(\n",
    "      np.zeros(feature_dim), center_cov, 1)[0]\n",
    "    centers.append(center)\n",
    "  features = []\n",
    "  for cluster_index in sbm_data.feature_memberships:\n",
    "    feature = np.random.multivariate_normal(centers[cluster_index], cluster_cov,\n",
    "                                            1)[0]\n",
    "    features.append(feature)\n",
    "  features = np.array(features)\n",
    "  if normalize_features:\n",
    "    features = normalize(features)\n",
    "  sbm_data.node_features = features\n",
    "\n",
    "\n",
    "def SimulateEdgeFeatures(sbm_data,\n",
    "                         feature_dim,\n",
    "                         center_distance=0.0,\n",
    "                         cluster_variance=1.0):\n",
    "  \"\"\"Generates edge feature distribution via inter-class vs intra-class.\n",
    "  Edge feature data is stored as an sbm_data attribute named `edge_feature`, a\n",
    "  dict from 2-tuples of node IDs to numpy vectors.\n",
    "  Edge features have two centers: one at (0, 0, ....) and one at\n",
    "  (center_distance, center_distance, ....) for inter-class and intra-class\n",
    "  edges (respectively). They are generated from a multivariate normal with\n",
    "  covariance matrix = cluster_variance * I_d.\n",
    "  Requires non-None `graph` and `graph_memberships` attributes in sbm_data.\n",
    "  Use SimulateSbm to generate them. Throws warning if either are None.\n",
    "  Args:\n",
    "    sbm_data: StochasticBlockModel dataclass to store result data.\n",
    "    feature_dim: (int) dimension of the multivariate normal.\n",
    "    center_distance: (float) per-dimension distance between the intra-class and\n",
    "      inter-class means. Increasing this makes the edge feature signal stronger.\n",
    "    cluster_variance: (float) variance of clusters around their centers.\n",
    "  Raises:\n",
    "    RuntimeWarning: if simulator has no graph or a graph with no nodes.\n",
    "  \"\"\"\n",
    "  if sbm_data.graph is None:\n",
    "    raise RuntimeWarning(\"SbmSimulator has no graph: no features generated.\")\n",
    "  if sbm_data.graph.num_vertices() == 0:\n",
    "    raise RuntimeWarning(\"graph has no nodes: no features generated.\")\n",
    "  if sbm_data.graph_memberships is None:\n",
    "    raise RuntimeWarning(\"graph has no memberships: no features generated.\")\n",
    "\n",
    "  center0 = np.zeros(shape=(feature_dim,))\n",
    "  center1 = np.ones(shape=(feature_dim,)) * center_distance\n",
    "  covariance = np.identity(feature_dim) * cluster_variance\n",
    "  sbm_data.edge_features = {}\n",
    "  for edge in sbm_data.graph.edges():\n",
    "    vertex1 = int(edge.source())\n",
    "    vertex2 = int(edge.target())\n",
    "    edge_tuple = tuple(sorted((vertex1, vertex2)))\n",
    "    if (sbm_data.graph_memberships[vertex1] ==\n",
    "        sbm_data.graph_memberships[vertex2]):\n",
    "      center = center1\n",
    "    else:\n",
    "      center = center0\n",
    "    sbm_data.edge_features[edge_tuple] = np.random.multivariate_normal(\n",
    "      center, covariance, 1)[0]\n",
    "\n",
    "\n",
    "def GenerateStochasticBlockModelWithFeatures(\n",
    "    num_vertices,\n",
    "    num_edges,\n",
    "    pi,\n",
    "    prop_mat,\n",
    "    out_degs=None,\n",
    "    feature_center_distance=0.0,\n",
    "    feature_dim=0,\n",
    "    num_feature_groups=1,\n",
    "    feature_group_match_type=MatchType.RANDOM,\n",
    "    feature_cluster_variance=1.0,\n",
    "    edge_feature_dim=0,\n",
    "    edge_center_distance=0.0,\n",
    "    edge_cluster_variance=1.0,\n",
    "    normalize_features=True):\n",
    "  \"\"\"Generates stochastic block model (SBM) with node features.\n",
    "  Args:\n",
    "    num_vertices: number of nodes in the graph.\n",
    "    num_edges: expected number of edges in the graph.\n",
    "    pi: interable of non-zero community size proportions. Must sum to 1.0.\n",
    "    prop_mat: square, symmetric matrix of community edge count rates. Example:\n",
    "      if diagonals are 2.0 and off-diagonals are 1.0, within-community edges are\n",
    "      twices as likely as between-community edges.\n",
    "    out_degs: Out-degree propensity for each node. If not provided, a constant\n",
    "      value will be used. Note that the values will be normalized inside each\n",
    "      group, if they are not already so.\n",
    "    feature_center_distance: distance between feature cluster centers. When this\n",
    "      is 0.0, the signal-to-noise ratio is 0.0. When equal to\n",
    "      feature_cluster_variance, SNR is 1.0.\n",
    "    feature_dim: dimension of node features.\n",
    "    num_feature_groups: number of feature clusters.\n",
    "    feature_group_match_type: see sbm_simulator.MatchType.\n",
    "    feature_cluster_variance: variance of feature clusters around their centers.\n",
    "      centers. Increasing this weakens node feature signal.\n",
    "    edge_feature_dim: dimension of edge features.\n",
    "    edge_center_distance: per-dimension distance between the intra-class and\n",
    "      inter-class means. Increasing this strengthens the edge feature signal.\n",
    "    edge_cluster_variance: variance of edge clusters around their centers.\n",
    "      Increasing this weakens the edge feature signal.\n",
    "  Returns:\n",
    "    result: a StochasticBlockModel data class.\n",
    "  \"\"\"\n",
    "  result = StochasticBlockModel()\n",
    "  SimulateSbm(result, num_vertices, num_edges, pi, prop_mat, out_degs)\n",
    "  SimulateFeatures(result, feature_center_distance,\n",
    "                   feature_dim,\n",
    "                   num_feature_groups,\n",
    "                   feature_group_match_type,\n",
    "                   feature_cluster_variance,\n",
    "                   normalize_features)\n",
    "  SimulateEdgeFeatures(result, edge_feature_dim,\n",
    "                       edge_center_distance,\n",
    "                       edge_cluster_variance)\n",
    "  return result\n",
    "\n",
    "\n",
    "# Helper function to create the \"Pi\" vector for the SBM model (the\n",
    "# ${num_communities}-simplex vector giving relative community sizes) from\n",
    "# the `community_size_slope` config field. See the config proto for details.\n",
    "def MakePi(num_communities: int, community_size_slope: float) -> np.ndarray:\n",
    "  pi = np.array(range(num_communities)) * community_size_slope\n",
    "  pi += np.ones(num_communities)\n",
    "  pi /= np.sum(pi)\n",
    "  return pi\n",
    "\n",
    "\n",
    "# Helper function to create the \"PropMat\" matrix for the SBM model (square\n",
    "# matrix giving inter-community Poisson means) from the config parameters,\n",
    "# particularly `p_to_q_ratio`. See the config proto for details.\n",
    "'''def MakePropMat(num_communities: int, p_to_q_ratio: float) -> np.ndarray:\n",
    "  prop_mat = np.ones((num_communities, num_communities))\n",
    "  np.fill_diagonal(prop_mat, p_to_q_ratio)\n",
    "  return prop_mat'''\n",
    "def MakePropMat(num_communities: int, p_to_q_ratio: float) -> np.ndarray:\n",
    "  prop_mat = np.ones((num_communities, num_communities))\n",
    "  np.fill_diagonal(prop_mat, p_to_q_ratio)\n",
    "  return prop_mat\n",
    "\n",
    "\n",
    "# Helper function to create a degree set that follows a power law for the\n",
    "# 'out_degs' parameter in SBM construction.\n",
    "def MakeDegrees(power_exponent, min_deg, num_vertices):\n",
    "  degrees = np.zeros(num_vertices)\n",
    "  k_min = min_deg\n",
    "  k_max = num_vertices\n",
    "  gamma = power_exponent\n",
    "  for i in range(num_vertices):\n",
    "      degrees[i] = int(power_law(k_min, k_max, np.random.uniform(0,1), gamma))\n",
    "  return degrees\n",
    "\n",
    "def convert_networkx(gt_graph):\n",
    "    # create a new empty NetworkX graph\n",
    "    nx_graph = nx.Graph()\n",
    "\n",
    "    # add nodes to the NetworkX graph\n",
    "    for node in gt_graph.vertices():\n",
    "        nx_graph.add_node(int(node))\n",
    "    # add edges to the NetworkX graph\n",
    "    for edge in gt_graph.edges():\n",
    "        src, dst = int(edge.source()), int(edge.target())\n",
    "        nx_graph.add_edge(src, dst)\n",
    "    nx_graph.remove_nodes_from(list(nx.isolates(nx_graph)))\n",
    "    return nx_graph\n",
    "def gt_to_nx(gt_graph, labels):\n",
    "    nx_graph = nx.Graph()\n",
    "    edge_list = [(int(e.source()), int(e.target())) for e in gt_graph.edges()]\n",
    "    nx_graph.add_edges_from(edge_list)\n",
    "    nx.set_node_attributes(nx_graph, {i: group for i, group in enumerate(labels)},\n",
    "                           \"group\")\n",
    "    return nx_graph\n",
    "\n",
    "# Helper function of MakeDegrees to construct power law samples\n",
    "def power_law(k_min, k_max, y, gamma):\n",
    "  return ((k_max**(-gamma+1) - k_min**(-gamma+1))*y  + k_min**(-gamma+1.0))**(1.0/(-gamma + 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                \"Unserializable object {} of type {}\".format(obj, type(obj))\n",
    "            )\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "def get_from_json(file_path):\n",
    "    with open(file_path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data\n",
    "\n",
    "def molloy_reed(g):\n",
    "  all_degree =   np.array(g.degree())[:,1]\n",
    "  degs = np.delete(all_degree,-1)\n",
    "  k = degs.mean()\n",
    "  k2 = np.mean(degs ** 2)\n",
    "  beta = k2/k\n",
    "  return beta\n",
    "\n",
    "def global_feature(g): \n",
    "    feature = {}\n",
    "    M = len(g.edges())\n",
    "    N = len(g)\n",
    "    degs =   np.array(g.degree())[:,1]\n",
    "    min_k = np.min(degs)\n",
    "    k1 = degs.mean()\n",
    "    k2 = np.mean(degs** 2)\n",
    "    div = k2 - k1**2\n",
    "    A = nx.to_scipy_sparse_array(g, weight='weight',dtype=float,format='csr')\n",
    "    adj_lams = np.sort(eigsh(A, k=N-1, which='LA', return_eigenvectors=False))\n",
    "    feature[\"nodes\"] = N\n",
    "    feature[\"edges\"] = M\n",
    "    feature[\"averagedegree\"] = k1\n",
    "    feature[\"heterogeneity\"] = div/k1\n",
    "    feature[\"density\"] = (2*M)/(N*(N-1))\n",
    "    feature[\"resilience\"] = molloy_reed(g)\n",
    "    #power_law_exponent = 1 + N / sum(np.log(degs/min_k))\n",
    "    feature[\"modularity\"] = nx_comm.modularity(g,nx_comm.label_propagation_communities(g))\n",
    "    try:\n",
    "        varepsilons = nx.algorithms.distance_measures.eccentricity(g).values()\n",
    "        feature[\"eccentricity\"]=  np.mean(list(varepsilons))\n",
    "        feature[\"diameter\"] = nx.algorithms.distance_measures.diameter(g)\n",
    "        feature[\"radius\"] = nx.algorithms.distance_measures.radius(g)\n",
    "    except:\n",
    "        lcc = max(nx.connected_components(g), key=len)\n",
    "        subGraph = g.subgraph(lcc)\n",
    "        varepsilons = nx.algorithms.distance_measures.eccentricity(subGraph).values()\n",
    "        feature[\"eccentricity\"]=  np.mean(list(varepsilons))\n",
    "        feature[\"diameter\"] = nx.algorithms.distance_measures.diameter(subGraph)\n",
    "        feature[\"radius\"] = nx.algorithms.distance_measures.radius(subGraph)\n",
    "    feature[\"spectral_radius\"]=adj_lams[-1]\n",
    "    feature[\"spectral_gap\"]=  adj_lams[-1]-adj_lams[-2]\n",
    "    feature[\"natural_connectivity\"]= np.log2(sum(np.exp(np.real(adj_lams)))/len(adj_lams))\n",
    "    feature[\"global_efficiency\"] = nx.algorithms.efficiency_measures.global_efficiency(g)\n",
    "    feature[\"assortativity\"] = nx.algorithms.assortativity.degree_assortativity_coefficient(g)\n",
    "    #global_properties =np.hstack((nodes, edges,density,resilience,heterogeneity,power_law_exponent, modularity,eccentricity,diameter,radius,spectral_radius,spectral_gap,natural_connectivity,assortativity))\n",
    "    return feature\n",
    "def gen_regular_graph(n,d):\n",
    "    # Generate a regular graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add edges between nodes in a regular pattern\n",
    "    for i in range(n):\n",
    "        for j in range(1, d+1):\n",
    "            G.add_edge(i, (i+j) % n)\n",
    "    return G\n",
    "\n",
    "def gen_sbm(n,p):\n",
    "    N = n\n",
    "    M = 3\n",
    "    NUM_CLUSTERS = 5\n",
    "    SLOPE = 0.1\n",
    "    FEATURE_DIM = 16\n",
    "    EDGE_DIM = 4\n",
    "    INTER_LINK_STRENGTH = 0.15\n",
    "    P2Q = 16.0\n",
    "    POWER_EXPONENT = 2.0\n",
    "    dataset = GenerateStochasticBlockModelWithFeatures(\n",
    "            num_vertices=N,\n",
    "            num_edges=N*5,\n",
    "            pi=MakePi(NUM_CLUSTERS, SLOPE),\n",
    "            #prop_mat=MakePropMat(NUM_CLUSTERS, P2Q),\n",
    "            prop_mat=MakePropMat(NUM_CLUSTERS, p),\n",
    "            out_degs=MakeDegrees(POWER_EXPONENT, M, N),\n",
    "            feature_center_distance=1.0,\n",
    "            feature_dim=FEATURE_DIM,\n",
    "            num_feature_groups=1,\n",
    "            feature_group_match_type=MatchType.GROUPED,\n",
    "            feature_cluster_variance=1.0,\n",
    "            edge_feature_dim=EDGE_DIM,\n",
    "            edge_center_distance=0.0,\n",
    "            edge_cluster_variance=1.0,\n",
    "            normalize_features=True)\n",
    "    G = gt_to_nx(dataset.graph, dataset.graph_memberships)\n",
    "    return G\n",
    "\n",
    "def gen_graph(cur_n,parameter, g_type):\n",
    "    if g_type == 'erdos_renyi':\n",
    "        g = nx.erdos_renyi_graph(n=cur_n, p=parameter)\n",
    "    elif g_type == 'powerlaw':\n",
    "        g = nx.powerlaw_cluster_graph(n=cur_n, m=3, p=0.05)\n",
    "    elif g_type == 'small-world':\n",
    "        g = nx.connected_watts_strogatz_graph(n=cur_n, k=parameter[0], p=parameter[1])\n",
    "    elif g_type == 'barabasi_albert':\n",
    "        g = nx.barabasi_albert_graph(n=cur_n, m=parameter)\n",
    "    elif g_type == 'regular':\n",
    "        g = gen_regular_graph(n=cur_n, d=parameter)\n",
    "    elif g_type == 'sbm':\n",
    "        g = gen_sbm(n=cur_n, p = parameter)\n",
    "    lcc = max(nx.connected_components(g), key=len)\n",
    "    Subgraph = g.subgraph(lcc)\n",
    "    return Subgraph\n",
    "\n",
    "\n",
    "def get_graph_degree(graph,feature,cur_n):\n",
    "    noderange = []\n",
    "    properties = []\n",
    "    files= []\n",
    "    for i in range(1,6):\n",
    "        print(i, end=(\", \"))\n",
    "        for graphtype in graph:\n",
    "            print(graphtype, end=(\", \"))\n",
    "            for parameter in graph[graphtype]:\n",
    "                G= gen_graph(cur_n, parameter, graphtype)\n",
    "                if graphtype == 'small-world':\n",
    "                    filename = graphtype+\"_\"+str(cur_n)+\"_\"+str(parameter[0])+\"_\"+str(parameter[1])+\"_\"+str(i)\n",
    "                else:\n",
    "                    filename = graphtype+\"_\"+str(cur_n)+\"_\"+str(parameter)+\"_\"+str(i)\n",
    "                files.append(filename)\n",
    "                #plt.figure(figsize=(15, 20), dpi=120)\n",
    "                #nx.draw(G,nodelist=G.nodes, font_color='white' ,node_size = 900, with_labels=True)\n",
    "                nx.write_edgelist(G, '../Dataset/SyntheticGraph/New/'+filename+'.txt',data=False)\n",
    "                feature[filename] = global_feature(G)\n",
    "                feature[filename][\"parameter\"] = parameter\n",
    "    return feature\n",
    "def get_graph_homogeneity(graph,feature):\n",
    "    noderange = []\n",
    "    properties = []\n",
    "    files= []\n",
    "    averagedegree = 4\n",
    "    for i in range(1,5):\n",
    "        print(i, end=(\", \"))\n",
    "        for graphtype in graph:\n",
    "            if graphtype == 'erdos_renyi':\n",
    "                parameter = [0.1 for n in graph[graphtype]]\n",
    "            elif graphtype =='small-world':\n",
    "                parameter = [averagedegree for n in graph[graphtype]]\n",
    "            elif graphtype =='barabasi_albert':\n",
    "                parameter = [3 for n in graph[graphtype]]\n",
    "            for k, cur_n in enumerate(graph[graphtype]):\n",
    "                G= gen_graph(cur_n, parameter[k], graphtype)\n",
    "                filename = graphtype+\"_\"+str(cur_n)+\"_\"+\"{:.3f}\".format(parameter[k])+\"_\"+str(i)\n",
    "                files.append(filename)\n",
    "                #plt.figure(figsize=(15, 20), dpi=120)\n",
    "                #nx.draw(G,nodelist=G.nodes, font_color='white' ,node_size = 900, with_labels=True)\n",
    "                nx.write_edgelist(G, '../Dataset/SyntheticGraph/Homogeneity/New/'+filename+'.txt',data=False)\n",
    "                feature[filename] = global_feature(G)\n",
    "                feature[filename][\"parameter\"] = parameter\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Degree: Different Average Degree of same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {'erdos_renyi': [0.005,0.025,0.05,0.075,0.1],\n",
    "         'barabasi_albert': [2,3,4,5,6],\n",
    "         'small-world': [2,3,4,5,6],\n",
    "        }\n",
    "graph = {'erdos_renyi': [0.008, 0.016, 0.024, 0.032, 0.04, 0.048, 0.056, 0.064, 0.072, 0.08],\n",
    "         'barabasi_albert': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "         #'small-world': [[i,0.1]for i in [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]],\n",
    "         'small-world': [[i,0.15]for i in [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]],\n",
    "        }\n",
    "numNodes = 250\n",
    "features = {}#get_from_json(\"../Dataset/featuresNew.json\")\n",
    "global_feature_degree = get_graph_degree(graph, {}, numNodes)\n",
    "#feature = {\"degree\": global_feature_degree} \n",
    "features[\"synthetic\"] =  global_feature_degree \n",
    "with open(\"../Dataset/featuresNew.json\", \"w\") as outfile:\n",
    "    json.dump(features, outfile, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, erdos_renyi, small-world, sbm, 2, erdos_renyi, small-world, sbm, 3, erdos_renyi, small-world, sbm, 4, erdos_renyi, small-world, sbm, 5, erdos_renyi, small-world, sbm, "
     ]
    }
   ],
   "source": [
    "graph = {'erdos_renyi': [0.005,0.025,0.05,0.075,0.1],\n",
    "         'barabasi_albert': [2,3,4,5,6],\n",
    "         'small-world': [2,3,4,5,6],\n",
    "        }\n",
    "graph = {'erdos_renyi': [0.001, 0.020, 0.030, 0.050, 0.0750, 0.100, 0.150, 0.200, 0.250,0.300],\n",
    "         'small-world': [[i,0.15]for i in [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]],\n",
    "         'sbm': [i for i in [5,10,15,20,25,30,35,40,45,50]],\n",
    "        }\n",
    "numNodes = 250\n",
    "features = get_from_json(\"../Dataset/featuresNew.json\")\n",
    "global_feature_degree = get_graph_degree(graph, features['synthetic'], numNodes)\n",
    "#feature = {\"degree\": global_feature_degree} \n",
    "features[\"synthetic\"] =  global_feature_degree \n",
    "with open(\"../Dataset/featuresNew.json\", \"w\") as outfile:\n",
    "    json.dump(features, outfile, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -C ../Dataset/SyntheticGraph/New -czf New.tar .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge homogeneity: Same Average Degrees of Different Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3, 4, 5, 6, 7, 8, 9, 10, "
     ]
    }
   ],
   "source": [
    "graph = {'erdos_renyi': [50,100,200,350,500],\n",
    "         'barabasi_albert':  [50,100,200,350,500],\n",
    "         'small-world':  [50,100,200,350,500],\n",
    "        }\n",
    "graph = {'erdos_renyi': [50,100,150, 200,250,300,350,400,450,500],\n",
    "         'barabasi_albert':  [50,100,150, 200,250,300,350,400,450,500],\n",
    "         'small-world': [50,100,150, 200,250,300,350,400,450,500],\n",
    "        }\n",
    "numNodes = 500\n",
    "features = get_from_json(\"../Dataset/featuresNew.json\")\n",
    "global_feature_homogeneity = get_graph_homogeneity(graph, {})\n",
    "features[\"homogeneity\"]=  global_feature_homogeneity\n",
    "with open(\"../Dataset/featuresNew.json\", \"w\") as outfile:\n",
    "    json.dump(features, outfile, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -C ../Dataset/SyntheticGraph/Degree/New -czf New_Degree.tar .\n",
    "!tar -C ../Dataset/SyntheticGraph/Homogeneity/New -czf New_Homogeneity.tar . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(graph_type,feature):\n",
    "    noderange = [50,750]\n",
    "    properties = []\n",
    "    files= []\n",
    "    for graphtype in graph_type:\n",
    "        print(graphtype, end=\", \")\n",
    "        for nodesize in noderange:\n",
    "            G= gen_graph(nodesize, graphtype)\n",
    "            filename = graphtype+\"_\"+str(nodesize)\n",
    "            files.append(filename)\n",
    "            #plt.figure(figsize=(15, 20), dpi=120)\n",
    "            #nx.draw(G,nodelist=G.nodes, font_color='white' ,node_size = 900, with_labels=True)\n",
    "            nx.write_edgelist(G, '../Dataset/SyntheticGraph/'+filename+'.txt',data=False)\n",
    "            feature[filename] = global_feature(G)\n",
    "    print(files)\n",
    "    return feature\n",
    "feature = get_from_json(\"../Dataset/features.json\")\n",
    "feature = get_graph(['erdos_renyi'], feature)\n",
    "with open(\"../Dataset/features.json\", \"w\") as outfile:\n",
    "    json.dump(feature, outfile, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Graph: GNNExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\"\"\"gengraph.py\n",
    "   Generating and manipulaton the synthetic graphs needed for the paper's experiments.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.colors as colors\n",
    "from scipy.sparse.linalg import eigsh\n",
    "# Set matplotlib backend to file writing\n",
    "#plt.switch_backend(\"agg\")\n",
    "\n",
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"synthetic_structsim.py\n",
    "    Utilities for generating certain graph shapes.\n",
    "\"\"\"\n",
    "import math\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "\"\"\" featgen.py\n",
    "Node feature generators.\n",
    "\"\"\"\n",
    "import abc\n",
    "\n",
    "\n",
    "class FeatureGen(metaclass=abc.ABCMeta):\n",
    "    \"\"\"Feature Generator base class.\"\"\"\n",
    "    @abc.abstractmethod\n",
    "    def gen_node_features(self, G):\n",
    "        pass\n",
    "\n",
    "\n",
    "class ConstFeatureGen(FeatureGen):\n",
    "    \"\"\"Constant Feature class.\"\"\"\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "\n",
    "    def gen_node_features(self, G):\n",
    "        feat_dict = {i:{'feat': np.array(self.val, dtype=np.float32)} for i in G.nodes()}\n",
    "        #print ('feat_dict[0][\"feat\"]:', feat_dict[0]['feat'].dtype)\n",
    "        nx.set_node_attributes(G, feat_dict)\n",
    "        #print ('G.nodes[0][\"feat\"]:', G.nodes[0]['feat'].dtype)\n",
    "\n",
    "\n",
    "class GaussianFeatureGen(FeatureGen):\n",
    "    \"\"\"Gaussian Feature class.\"\"\"\n",
    "    def __init__(self, mu, sigma):\n",
    "        self.mu = mu\n",
    "        if sigma.ndim < 2:\n",
    "            self.sigma = np.diag(sigma)\n",
    "        else:\n",
    "            self.sigma = sigma\n",
    "\n",
    "    def gen_node_features(self, G):\n",
    "        feat = np.random.multivariate_normal(self.mu, self.sigma, G.number_of_nodes())\n",
    "        feat_dict = {\n",
    "                i: {\"feat\": feat[i]} for i in range(feat.shape[0])\n",
    "            }\n",
    "        nx.set_node_attributes(G, feat_dict)\n",
    "\n",
    "\n",
    "class GridFeatureGen(FeatureGen):\n",
    "    \"\"\"Grid Feature class.\"\"\"\n",
    "    def __init__(self, mu, sigma, com_choices):\n",
    "        self.mu = mu                    # Mean\n",
    "        self.sigma = sigma              # Variance\n",
    "        self.com_choices = com_choices  # List of possible community labels\n",
    "\n",
    "    def gen_node_features(self, G):\n",
    "        # Generate community assignment\n",
    "        community_dict = {\n",
    "            n: self.com_choices[0] if G.degree(n) < 4 else self.com_choices[1]\n",
    "            for n in G.nodes()\n",
    "        }\n",
    "\n",
    "        # Generate random variable\n",
    "        s = np.random.normal(self.mu, self.sigma, G.number_of_nodes())\n",
    "\n",
    "        # Generate features\n",
    "        feat_dict = {\n",
    "            n: {\"feat\": np.asarray([community_dict[n], s[i]])}\n",
    "            for i, n in enumerate(G.nodes())\n",
    "        }\n",
    "\n",
    "        nx.set_node_attributes(G, feat_dict)\n",
    "        return community_dict\n",
    "    \n",
    "    \n",
    "# Following GraphWave's representation of structural similarity\n",
    "\n",
    "\n",
    "def clique(start, nb_nodes, nb_to_remove=0, role_start=0):\n",
    "    \"\"\" Defines a clique (complete graph on nb_nodes nodes,\n",
    "    with nb_to_remove  edges that will have to be removed),\n",
    "    index of nodes starting at start\n",
    "    and role_ids at role_start\n",
    "    INPUT:\n",
    "    -------------\n",
    "    start       :    starting index for the shape\n",
    "    nb_nodes    :    int correspondingraph to the nb of nodes in the clique\n",
    "    role_start  :    starting index for the roles\n",
    "    nb_to_remove:    int-- numb of edges to remove (unif at RDM)\n",
    "    OUTPUT:\n",
    "    -------------\n",
    "    graph       :    a house shape graph, with ids beginning at start\n",
    "    roles       :    list of the roles of the nodes (indexed starting at\n",
    "                     role_start)\n",
    "    \"\"\"\n",
    "    a = np.ones((nb_nodes, nb_nodes))\n",
    "    np.fill_diagonal(a, 0)\n",
    "    graph = nx.from_numpy_matrix(a)\n",
    "    edge_list = graph.edges().keys()\n",
    "    roles = [role_start] * nb_nodes\n",
    "    if nb_to_remove > 0:\n",
    "        lst = np.random.choice(len(edge_list), nb_to_remove, replace=False)\n",
    "        to_delete = [edge_list[e] for e in lst]\n",
    "        graph.remove_edges_from(to_delete)\n",
    "        for e in lst:\n",
    "            roles[edge_list[e][0]] += 1\n",
    "            roles[edge_list[e][1]] += 1\n",
    "    mapping_graph = {k: (k + start) for k in range(nb_nodes)}\n",
    "    graph = nx.relabel_nodes(graph, mapping_graph)\n",
    "    return graph, roles\n",
    "\n",
    "\n",
    "def cycle(start, len_cycle, role_start=0):\n",
    "    \"\"\"Builds a cycle graph, with index of nodes starting at start\n",
    "    and role_ids at role_start\n",
    "    INPUT:\n",
    "    -------------\n",
    "    start       :    starting index for the shape\n",
    "    role_start  :    starting index for the roles\n",
    "    OUTPUT:\n",
    "    -------------\n",
    "    graph       :    a house shape graph, with ids beginning at start\n",
    "    roles       :    list of the roles of the nodes (indexed starting at\n",
    "                     role_start)\n",
    "    \"\"\"\n",
    "    graph = nx.Graph()\n",
    "    graph.add_nodes_from(range(start, start + len_cycle))\n",
    "    for i in range(len_cycle - 1):\n",
    "        graph.add_edges_from([(start + i, start + i + 1)])\n",
    "    graph.add_edges_from([(start + len_cycle - 1, start)])\n",
    "    roles = [role_start] * len_cycle\n",
    "    return graph, roles\n",
    "\n",
    "\n",
    "def diamond(start, role_start=0):\n",
    "    \"\"\"Builds a diamond graph, with index of nodes starting at start\n",
    "    and role_ids at role_start\n",
    "    INPUT:\n",
    "    -------------\n",
    "    start       :    starting index for the shape\n",
    "    role_start  :    starting index for the roles\n",
    "    OUTPUT:\n",
    "    -------------\n",
    "    graph       :    a house shape graph, with ids beginning at start\n",
    "    roles       :    list of the roles of the nodes (indexed starting at\n",
    "                     role_start)\n",
    "    \"\"\"\n",
    "    graph = nx.Graph()\n",
    "    graph.add_nodes_from(range(start, start + 6))\n",
    "    graph.add_edges_from(\n",
    "        [\n",
    "            (start, start + 1),\n",
    "            (start + 1, start + 2),\n",
    "            (start + 2, start + 3),\n",
    "            (start + 3, start),\n",
    "        ]\n",
    "    )\n",
    "    graph.add_edges_from(\n",
    "        [\n",
    "            (start + 4, start),\n",
    "            (start + 4, start + 1),\n",
    "            (start + 4, start + 2),\n",
    "            (start + 4, start + 3),\n",
    "        ]\n",
    "    )\n",
    "    graph.add_edges_from(\n",
    "        [\n",
    "            (start + 5, start),\n",
    "            (start + 5, start + 1),\n",
    "            (start + 5, start + 2),\n",
    "            (start + 5, start + 3),\n",
    "        ]\n",
    "    )\n",
    "    roles = [role_start] * 6\n",
    "    return graph, roles\n",
    "\n",
    "\n",
    "def tree(start, height, r=2, role_start=0):\n",
    "    \"\"\"Builds a balanced r-tree of height h\n",
    "    INPUT:\n",
    "    -------------\n",
    "    start       :    starting index for the shape\n",
    "    height      :    int height of the tree \n",
    "    r           :    int number of branches per node \n",
    "    role_start  :    starting index for the roles\n",
    "    OUTPUT:\n",
    "    -------------\n",
    "    graph       :    a tree shape graph, with ids beginning at start\n",
    "    roles       :    list of the roles of the nodes (indexed starting at role_start)\n",
    "    \"\"\"\n",
    "    graph = nx.balanced_tree(r, height)\n",
    "    roles = [0] * graph.number_of_nodes()\n",
    "    return graph, roles\n",
    "\n",
    "\n",
    "def fan(start, nb_branches, role_start=0):\n",
    "    \"\"\"Builds a fan-like graph, with index of nodes starting at start\n",
    "    and role_ids at role_start\n",
    "    INPUT:\n",
    "    -------------\n",
    "    nb_branches :    int correspondingraph to the nb of fan branches\n",
    "    start       :    starting index for the shape\n",
    "    role_start  :    starting index for the roles\n",
    "    OUTPUT:\n",
    "    -------------\n",
    "    graph       :    a house shape graph, with ids beginning at start\n",
    "    roles       :    list of the roles of the nodes (indexed starting at\n",
    "                     role_start)\n",
    "    \"\"\"\n",
    "    graph, roles = star(start, nb_branches, role_start=role_start)\n",
    "    for k in range(1, nb_branches - 1):\n",
    "        roles[k] += 1\n",
    "        roles[k + 1] += 1\n",
    "        graph.add_edges_from([(start + k, start + k + 1)])\n",
    "    return graph, roles\n",
    "\n",
    "\n",
    "def ba(start, width, role_start=0, m=5):\n",
    "    \"\"\"Builds a BA preferential attachment graph, with index of nodes starting at start\n",
    "    and role_ids at role_start\n",
    "    INPUT:\n",
    "    -------------\n",
    "    start       :    starting index for the shape\n",
    "    width       :    int size of the graph\n",
    "    role_start  :    starting index for the roles\n",
    "    OUTPUT:\n",
    "    -------------\n",
    "    graph       :    a house shape graph, with ids beginning at start\n",
    "    roles       :    list of the roles of the nodes (indexed starting at\n",
    "                     role_start)\n",
    "    \"\"\"\n",
    "    graph = nx.barabasi_albert_graph(width, m)\n",
    "    graph.add_nodes_from(range(start, start + width))\n",
    "    nids = sorted(graph)\n",
    "    mapping = {nid: start + i for i, nid in enumerate(nids)}\n",
    "    graph = nx.relabel_nodes(graph, mapping)\n",
    "    roles = [role_start for i in range(width)]\n",
    "    return graph, roles\n",
    "\n",
    "\n",
    "def house(start, role_start=0):\n",
    "    \"\"\"Builds a house-like  graph, with index of nodes starting at start\n",
    "    and role_ids at role_start\n",
    "    INPUT:\n",
    "    -------------\n",
    "    start       :    starting index for the shape\n",
    "    role_start  :    starting index for the roles\n",
    "    OUTPUT:\n",
    "    -------------\n",
    "    graph       :    a house shape graph, with ids beginning at start\n",
    "    roles       :    list of the roles of the nodes (indexed starting at\n",
    "                     role_start)\n",
    "    \"\"\"\n",
    "    graph = nx.Graph()\n",
    "    graph.add_nodes_from(range(start, start + 5))\n",
    "    graph.add_edges_from(\n",
    "        [\n",
    "            (start, start + 1),\n",
    "            (start + 1, start + 2),\n",
    "            (start + 2, start + 3),\n",
    "            (start + 3, start),\n",
    "        ]\n",
    "    )\n",
    "    # graph.add_edges_from([(start, start + 2), (start + 1, start + 3)])\n",
    "    graph.add_edges_from([(start + 4, start), (start + 4, start + 1)])\n",
    "    roles = [role_start, role_start, role_start + 1, role_start + 1, role_start + 2]\n",
    "    return graph, roles\n",
    "\n",
    "\n",
    "def grid(start, dim=2, role_start=0):\n",
    "    \"\"\" Builds a 2by2 grid\n",
    "    \"\"\"\n",
    "    grid_G = nx.grid_graph([dim, dim])\n",
    "    grid_G = nx.convert_node_labels_to_integers(grid_G, first_label=start)\n",
    "    roles = [role_start for i in grid_G.nodes()]\n",
    "    return grid_G, roles\n",
    "\n",
    "\n",
    "def star(start, nb_branches, role_start=0):\n",
    "    \"\"\"Builds a star graph, with index of nodes starting at start\n",
    "    and role_ids at role_start\n",
    "    INPUT:\n",
    "    -------------\n",
    "    nb_branches :    int correspondingraph to the nb of star branches\n",
    "    start       :    starting index for the shape\n",
    "    role_start  :    starting index for the roles\n",
    "    OUTPUT:\n",
    "    -------------\n",
    "    graph       :    a house shape graph, with ids beginning at start\n",
    "    roles       :    list of the roles of the nodes (indexed starting at\n",
    "                     role_start)\n",
    "    \"\"\"\n",
    "    graph = nx.Graph()\n",
    "    graph.add_nodes_from(range(start, start + nb_branches + 1))\n",
    "    for k in range(1, nb_branches + 1):\n",
    "        graph.add_edges_from([(start, start + k)])\n",
    "    roles = [role_start + 1] * (nb_branches + 1)\n",
    "    roles[0] = role_start\n",
    "    return graph, roles\n",
    "\n",
    "\n",
    "def path(start, width, role_start=0):\n",
    "    \"\"\"Builds a path graph, with index of nodes starting at start\n",
    "    and role_ids at role_start\n",
    "    INPUT:\n",
    "    -------------\n",
    "    start       :    starting index for the shape\n",
    "    width       :    int length of the path\n",
    "    role_start  :    starting index for the roles\n",
    "    OUTPUT:\n",
    "    -------------\n",
    "    graph       :    a house shape graph, with ids beginning at start\n",
    "    roles       :    list of the roles of the nodes (indexed starting at\n",
    "                     role_start)\n",
    "    \"\"\"\n",
    "    graph = nx.Graph()\n",
    "    graph.add_nodes_from(range(start, start + width))\n",
    "    for i in range(width - 1):\n",
    "        graph.add_edges_from([(start + i, start + i + 1)])\n",
    "    roles = [role_start] * width\n",
    "    roles[0] = role_start + 1\n",
    "    roles[-1] = role_start + 1\n",
    "    return graph, roles\n",
    "\n",
    "\n",
    "def build_graph(\n",
    "    width_basis,\n",
    "    basis_type,\n",
    "    list_shapes,\n",
    "    start=0,\n",
    "    rdm_basis_plugins=False,\n",
    "    add_random_edges=0,\n",
    "    m=5,\n",
    "):\n",
    "    \"\"\"This function creates a basis (scale-free, path, or cycle)\n",
    "    and attaches elements of the type in the list randomly along the basis.\n",
    "    Possibility to add random edges afterwards.\n",
    "    INPUT:\n",
    "    --------------------------------------------------------------------------------------\n",
    "    width_basis      :      width (in terms of number of nodes) of the basis\n",
    "    basis_type       :      (torus, string, or cycle)\n",
    "    shapes           :      list of shape list (1st arg: type of shape,\n",
    "                            next args:args for building the shape,\n",
    "                            except for the start)\n",
    "    start            :      initial nb for the first node\n",
    "    rdm_basis_plugins:      boolean. Should the shapes be randomly placed\n",
    "                            along the basis (True) or regularly (False)?\n",
    "    add_random_edges :      nb of edges to randomly add on the structure\n",
    "    m                :      number of edges to attach to existing node (for BA graph)\n",
    "    OUTPUT:\n",
    "    --------------------------------------------------------------------------------------\n",
    "    basis            :      a nx graph with the particular shape\n",
    "    role_ids         :      labels for each role\n",
    "    plugins          :      node ids with the attached shapes\n",
    "    \"\"\"\n",
    "    if basis_type == \"ba\":\n",
    "        \n",
    "        basis, role_id = eval(basis_type)(start, width_basis, m=m)\n",
    "    else:\n",
    "        basis, role_id = eval(basis_type)(start, width_basis)\n",
    "    n_basis, n_shapes = nx.number_of_nodes(basis), len(list_shapes)\n",
    "    start += n_basis  # indicator of the id of the next node\n",
    "\n",
    "    # Sample (with replacement) where to attach the new motifs\n",
    "    if rdm_basis_plugins is True:\n",
    "        plugins = np.random.choice(n_basis, n_shapes, replace=False)\n",
    "    else:\n",
    "        spacing = math.floor(n_basis / n_shapes)\n",
    "        plugins = [int(k * spacing) for k in range(n_shapes)]\n",
    "    seen_shapes = {\"basis\": [0, n_basis]}\n",
    "\n",
    "    for shape_id, shape in enumerate(list_shapes):\n",
    "        shape_type = shape[0]\n",
    "        args = [start]\n",
    "        if len(shape) > 1:\n",
    "            args += shape[1:]\n",
    "        args += [0]\n",
    "        graph_s, roles_graph_s = eval(shape_type)(*args)\n",
    "        n_s = nx.number_of_nodes(graph_s)\n",
    "        try:\n",
    "            col_start = seen_shapes[shape_type][0]\n",
    "        except:\n",
    "            col_start = np.max(role_id) + 1\n",
    "            seen_shapes[shape_type] = [col_start, n_s]\n",
    "        # Attach the shape to the basis\n",
    "        basis.add_nodes_from(graph_s.nodes())\n",
    "        basis.add_edges_from(graph_s.edges())\n",
    "        basis.add_edges_from([(start, plugins[shape_id])])\n",
    "        if shape_type == \"cycle\":\n",
    "            if np.random.random() > 0.5:\n",
    "                a = np.random.randint(1, 4)\n",
    "                b = np.random.randint(1, 4)\n",
    "                basis.add_edges_from([(a + start, b + plugins[shape_id])])\n",
    "        temp_labels = [r + col_start for r in roles_graph_s]\n",
    "        # temp_labels[0] += 100 * seen_shapes[shape_type][0]\n",
    "        role_id += temp_labels\n",
    "        start += n_s\n",
    "\n",
    "    if add_random_edges > 0:\n",
    "        # add random edges between nodes:\n",
    "        for p in range(add_random_edges):\n",
    "            src, dest = np.random.choice(nx.number_of_nodes(basis), 2, replace=False)\n",
    "            basis.add_edges_from([(src, dest)])\n",
    "\n",
    "    return basis, role_id, plugins\n",
    "\n",
    "####################################\n",
    "#\n",
    "# Experiment utilities\n",
    "#\n",
    "####################################\n",
    "def perturb(graph_list, p):\n",
    "    \"\"\" Perturb the list of (sparse) graphs by adding/removing edges.\n",
    "    Args:\n",
    "        p: proportion of added edges based on current number of edges.\n",
    "    Returns:\n",
    "        A list of graphs that are perturbed from the original graphs.\n",
    "    \"\"\"\n",
    "    perturbed_graph_list = []\n",
    "    for G_original in graph_list:\n",
    "        G = G_original.copy()\n",
    "        edge_count = int(G.number_of_edges() * p)\n",
    "        # randomly add the edges between a pair of nodes without an edge.\n",
    "        for _ in range(edge_count):\n",
    "            while True:\n",
    "                u = np.random.randint(0, G.number_of_nodes())\n",
    "                v = np.random.randint(0, G.number_of_nodes())\n",
    "                if (not G.has_edge(u, v)) and (u != v):\n",
    "                    break\n",
    "            G.add_edge(u, v)\n",
    "        perturbed_graph_list.append(G)\n",
    "    return perturbed_graph_list\n",
    "\n",
    "\n",
    "def join_graph(G1, G2, n_pert_edges):\n",
    "    \"\"\" Join two graphs along matching nodes, then perturb the resulting graph.\n",
    "    Args:\n",
    "        G1, G2: Networkx graphs to be joined.\n",
    "        n_pert_edges: number of perturbed edges.\n",
    "    Returns:\n",
    "        A new graph, result of merging and perturbing G1 and G2.\n",
    "    \"\"\"\n",
    "    assert n_pert_edges > 0\n",
    "    F = nx.compose(G1, G2)\n",
    "    edge_cnt = 0\n",
    "    while edge_cnt < n_pert_edges:\n",
    "        node_1 = np.random.choice(G1.nodes())\n",
    "        node_2 = np.random.choice(G2.nodes())\n",
    "        F.add_edge(node_1, node_2)\n",
    "        edge_cnt += 1\n",
    "    return F\n",
    "\n",
    "\n",
    "def preprocess_input_graph(G, labels, normalize_adj=False):\n",
    "    \"\"\" Load an existing graph to be converted for the experiments.\n",
    "    Args:\n",
    "        G: Networkx graph to be loaded.\n",
    "        labels: Associated node labels.\n",
    "        normalize_adj: Should the method return a normalized adjacency matrix.\n",
    "    Returns:\n",
    "        A dictionary containing adjacency, node features and labels\n",
    "    \"\"\"\n",
    "    adj = np.array(nx.to_numpy_matrix(G))\n",
    "    if normalize_adj:\n",
    "        sqrt_deg = np.diag(1.0 / np.sqrt(np.sum(adj, axis=0, dtype=float).squeeze()))\n",
    "        adj = np.matmul(np.matmul(sqrt_deg, adj), sqrt_deg)\n",
    "\n",
    "    existing_node = list(G.nodes)[-1]\n",
    "    feat_dim = G.nodes[existing_node][\"feat\"].shape[0]\n",
    "    f = np.zeros((G.number_of_nodes(), feat_dim), dtype=float)\n",
    "    for i, u in enumerate(G.nodes()):\n",
    "        f[i, :] = G.nodes[u][\"feat\"]\n",
    "\n",
    "    # add batch dim\n",
    "    adj = np.expand_dims(adj, axis=0)\n",
    "    f = np.expand_dims(f, axis=0)\n",
    "    labels = np.expand_dims(labels, axis=0)\n",
    "    return {\"adj\": adj, \"feat\": f, \"labels\": labels}\n",
    "\n",
    "\n",
    "####################################\n",
    "#\n",
    "# Generating synthetic graphs\n",
    "#\n",
    "###################################\n",
    "def bahouse(nb_shapes=100, width_basis=60, feature_generator=None, m=5):\n",
    "    \"\"\" Synthetic Graph #1:\n",
    "    Start with Barabasi-Albert graph and attach house-shaped subgraphs.\n",
    "    Args:\n",
    "        nb_shapes         :  The number of shapes (here 'houses') that should be added to the base graph.\n",
    "        width_basis       :  The width of the basis graph (here 'Barabasi-Albert' random graph).\n",
    "        feature_generator :  A `FeatureGenerator` for node features. If `None`, add constant features to nodes.\n",
    "        m                 :  number of edges to attach to existing node (for BA graph)\n",
    "    Returns:\n",
    "        G                 :  A networkx graph\n",
    "        role_id           :  A list with length equal to number of nodes in the entire graph (basis\n",
    "                          :  + shapes). role_id[i] is the ID of the role of node i. It is the label.\n",
    "        name              :  A graph identifier\n",
    "    \"\"\"\n",
    "    basis_type = \"ba\"\n",
    "    list_shapes = [[\"house\"]] * nb_shapes\n",
    "\n",
    "    plt.figure(figsize=(8, 6), dpi=300)\n",
    "\n",
    "    G, role_id, _ = build_graph(\n",
    "        width_basis, basis_type, list_shapes, start=0, m=5\n",
    "    )\n",
    "    G = perturb([G], 0.01)[0]\n",
    "\n",
    "    if feature_generator is None:\n",
    "        feature_generator = ConstFeatureGen(1)\n",
    "    feature_generator.gen_node_features(G)\n",
    "\n",
    "    name = basis_type + \"_\" + str(width_basis) + \"_\" + str(nb_shapes) + \"_house\"\n",
    "    return G, role_id, name\n",
    "\n",
    "def bafan(nb_shapes=100, width_basis=60, feature_generator=None, m=5):\n",
    "    \"\"\" Synthetic Graph #1:\n",
    "    Start with Barabasi-Albert graph and attach house-shaped subgraphs.\n",
    "    Args:\n",
    "        nb_shapes         :  The number of shapes (here 'houses') that should be added to the base graph.\n",
    "        width_basis       :  The width of the basis graph (here 'Barabasi-Albert' random graph).\n",
    "        feature_generator :  A `FeatureGenerator` for node features. If `None`, add constant features to nodes.\n",
    "        m                 :  number of edges to attach to existing node (for BA graph)\n",
    "    Returns:\n",
    "        G                 :  A networkx graph\n",
    "        role_id           :  A list with length equal to number of nodes in the entire graph (basis\n",
    "                          :  + shapes). role_id[i] is the ID of the role of node i. It is the label.\n",
    "        name              :  A graph identifier\n",
    "    \"\"\"\n",
    "    basis_type = \"ba\"\n",
    "    list_shapes = [[\"fan\"]] * nb_shapes\n",
    "\n",
    "    plt.figure(figsize=(8, 6), dpi=300)\n",
    "\n",
    "    G, role_id, _ = build_graph(\n",
    "        width_basis, basis_type, list_shapes, start=0, m=5\n",
    "    )\n",
    "    G = perturb([G], 0.01)[0]\n",
    "\n",
    "    if feature_generator is None:\n",
    "        feature_generator = ConstFeatureGen(1)\n",
    "    feature_generator.gen_node_features(G)\n",
    "\n",
    "    name = basis_type + \"_\" + str(width_basis) + \"_\" + str(nb_shapes) + \"_fan\"\n",
    "    return G, role_id, name\n",
    "\n",
    "def baclique(nb_shapes=100, width_basis=60, feature_generator=None, m=5):\n",
    "    \"\"\" Synthetic Graph #1:\n",
    "    Start with Barabasi-Albert graph and attach house-shaped subgraphs.\n",
    "    Args:\n",
    "        nb_shapes         :  The number of shapes (here 'houses') that should be added to the base graph.\n",
    "        width_basis       :  The width of the basis graph (here 'Barabasi-Albert' random graph).\n",
    "        feature_generator :  A `FeatureGenerator` for node features. If `None`, add constant features to nodes.\n",
    "        m                 :  number of edges to attach to existing node (for BA graph)\n",
    "    Returns:\n",
    "        G                 :  A networkx graph\n",
    "        role_id           :  A list with length equal to number of nodes in the entire graph (basis\n",
    "                          :  + shapes). role_id[i] is the ID of the role of node i. It is the label.\n",
    "        name              :  A graph identifier\n",
    "    \"\"\"\n",
    "    basis_type = \"ba\"\n",
    "    list_shapes = [[\"clique\"]] * nb_shapes\n",
    "\n",
    "    plt.figure(figsize=(8, 6), dpi=300)\n",
    "\n",
    "    G, role_id, _ = build_graph(\n",
    "        width_basis, basis_type, list_shapes, start=0, m=5\n",
    "    )\n",
    "    G = perturb([G], 0.01)[0]\n",
    "\n",
    "    if feature_generator is None:\n",
    "        feature_generator = ConstFeatureGen(1)\n",
    "    feature_generator.gen_node_features(G)\n",
    "\n",
    "    name = basis_type + \"_\" + str(width_basis) + \"_\" + str(nb_shapes) + \"_clique\"\n",
    "    return G, role_id, name\n",
    "\n",
    "def bastar(nb_shapes=100, width_basis=60, feature_generator=None, m=5):\n",
    "    \"\"\" Synthetic Graph #1:\n",
    "    Start with Barabasi-Albert graph and attach house-shaped subgraphs.\n",
    "    Args:\n",
    "        nb_shapes         :  The number of shapes (here 'houses') that should be added to the base graph.\n",
    "        width_basis       :  The width of the basis graph (here 'Barabasi-Albert' random graph).\n",
    "        feature_generator :  A `FeatureGenerator` for node features. If `None`, add constant features to nodes.\n",
    "        m                 :  number of edges to attach to existing node (for BA graph)\n",
    "    Returns:\n",
    "        G                 :  A networkx graph\n",
    "        role_id           :  A list with length equal to number of nodes in the entire graph (basis\n",
    "                          :  + shapes). role_id[i] is the ID of the role of node i. It is the label.\n",
    "        name              :  A graph identifier\n",
    "    \"\"\"\n",
    "    basis_type = \"ba\"\n",
    "    list_shapes = [[\"star\"]] * nb_shapes\n",
    "\n",
    "    plt.figure(figsize=(8, 6), dpi=300)\n",
    "\n",
    "    G, role_id, _ = build_graph(\n",
    "        width_basis, basis_type, list_shapes, start=0, m=5\n",
    "    )\n",
    "    G = perturb([G], 0.01)[0]\n",
    "\n",
    "    if feature_generator is None:\n",
    "        feature_generator = ConstFeatureGen(1)\n",
    "    feature_generator.gen_node_features(G)\n",
    "\n",
    "    name = basis_type + \"_\" + str(width_basis) + \"_\" + str(nb_shapes) + \"_star\"\n",
    "    return G, role_id, name\n",
    "\n",
    "def badiamond(nb_shapes=100, width_basis=60, feature_generator=None, m=5):\n",
    "    \"\"\" Synthetic Graph #1:\n",
    "    Start with Barabasi-Albert graph and attach house-shaped subgraphs.\n",
    "    Args:\n",
    "        nb_shapes         :  The number of shapes (here 'houses') that should be added to the base graph.\n",
    "        width_basis       :  The width of the basis graph (here 'Barabasi-Albert' random graph).\n",
    "        feature_generator :  A `FeatureGenerator` for node features. If `None`, add constant features to nodes.\n",
    "        m                 :  number of edges to attach to existing node (for BA graph)\n",
    "    Returns:\n",
    "        G                 :  A networkx graph\n",
    "        role_id           :  A list with length equal to number of nodes in the entire graph (basis\n",
    "                          :  + shapes). role_id[i] is the ID of the role of node i. It is the label.\n",
    "        name              :  A graph identifier\n",
    "    \"\"\"\n",
    "    basis_type = \"ba\"\n",
    "    list_shapes = [[\"diamond\"]] * nb_shapes\n",
    "\n",
    "    plt.figure(figsize=(8, 6), dpi=300)\n",
    "\n",
    "    G, role_id, _ = build_graph(\n",
    "        width_basis, basis_type, list_shapes, start=0, m=5\n",
    "    )\n",
    "    G = perturb([G], 0.01)[0]\n",
    "\n",
    "    if feature_generator is None:\n",
    "        feature_generator = ConstFeatureGen(1)\n",
    "    feature_generator.gen_node_features(G)\n",
    "\n",
    "    name = basis_type + \"_\" + str(width_basis) + \"_\" + str(nb_shapes) + \"_diamond\"\n",
    "    return G, role_id, name\n",
    "\n",
    "\n",
    "def bacycle(nb_shapes=100, width_basis=60, feature_generator=None, m=5):\n",
    "    \"\"\" Synthetic Graph #1:\n",
    "    Start with Barabasi-Albert graph and attach house-shaped subgraphs.\n",
    "    Args:\n",
    "        nb_shapes         :  The number of shapes (here 'houses') that should be added to the base graph.\n",
    "        width_basis       :  The width of the basis graph (here 'Barabasi-Albert' random graph).\n",
    "        feature_generator :  A `FeatureGenerator` for node features. If `None`, add constant features to nodes.\n",
    "        m                 :  number of edges to attach to existing node (for BA graph)\n",
    "    Returns:\n",
    "        G                 :  A networkx graph\n",
    "        role_id           :  A list with length equal to number of nodes in the entire graph (basis\n",
    "                          :  + shapes). role_id[i] is the ID of the role of node i. It is the label.\n",
    "        name              :  A graph identifier\n",
    "    \"\"\"\n",
    "    basis_type = \"ba\"\n",
    "    list_shapes = [[\"cycle\"]] * nb_shapes\n",
    "\n",
    "    plt.figure(figsize=(8, 6), dpi=300)\n",
    "\n",
    "    G, role_id, _ = build_graph(\n",
    "        width_basis, basis_type, list_shapes, start=0, m=5\n",
    "    )\n",
    "    G = perturb([G], 0.01)[0]\n",
    "\n",
    "    if feature_generator is None:\n",
    "        feature_generator = ConstFeatureGen(1)\n",
    "    feature_generator.gen_node_features(G)\n",
    "\n",
    "    name = basis_type + \"_\" + str(width_basis) + \"_\" + str(nb_shapes) + \"_cycle\"\n",
    "    return G, role_id, name\n",
    "\n",
    "\n",
    "def bagrid(nb_shapes=100, width_basis=60, feature_generator=None, m=5):\n",
    "    \"\"\" Synthetic Graph #3:\n",
    "    Start with Barabasi-Albert graph and attach grid-shaped subgraphs.\n",
    "    Args:\n",
    "        nb_shapes         :  The number of shapes (here 'grid') that should be added to the base graph.\n",
    "        width_basis       :  The width of the basis graph (here 'Barabasi-Albert' random graph).\n",
    "        feature_generator :  A `FeatureGenerator` for node features. If `None`, add constant features to nodes.\n",
    "        m                 :  number of edges to attach to existing node (for BA graph)\n",
    "    Returns:\n",
    "        G                 :  A networkx graph\n",
    "        role_id           :  Role ID for each node in synthetic graph.\n",
    "        name              :  A graph identifier\n",
    "    \"\"\"\n",
    "    basis_type = \"ba\"\n",
    "    list_shapes = [[\"grid\", 3]] * nb_shapes\n",
    "\n",
    "    plt.figure(figsize=(8, 6), dpi=300)\n",
    "\n",
    "    G, role_id, _ = build_graph(\n",
    "        width_basis, basis_type, list_shapes, start=0, m=5\n",
    "    )\n",
    "    G = perturb([G], 0.01)[0]\n",
    "\n",
    "    if feature_generator is None:\n",
    "        feature_generator = ConstFeatureGen(1)\n",
    "    feature_generator.gen_node_features(G)\n",
    "\n",
    "    name = basis_type + \"_\" + str(width_basis) + \"_\" + str(nb_shapes)  + \"_grid\"\n",
    "    return G, role_id, name\n",
    "\n",
    "def treecycle(nb_shapes=100, width_basis=4, feature_generator=None, m=4):\n",
    "    \"\"\" Synthetic Graph #4:\n",
    "    Start with a tree and attach cycle-shaped subgraphs.\n",
    "    Args:\n",
    "        nb_shapes         :  The number of shapes (here 'houses') that should be added to the base graph.\n",
    "        width_basis       :  The width of the basis graph (here a random 'Tree').\n",
    "        feature_generator :  A `FeatureGenerator` for node features. If `None`, add constant features to nodes.\n",
    "        m                 :  The tree depth.\n",
    "    Returns:\n",
    "        G                 :  A networkx graph\n",
    "        role_id           :  Role ID for each node in synthetic graph\n",
    "        name              :  A graph identifier\n",
    "    \"\"\"\n",
    "    basis_type = \"tree\"\n",
    "    list_shapes = [[\"cycle\", 6]] * nb_shapes\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6), dpi=300)\n",
    "\n",
    "    G, role_id, plugins = build_graph(\n",
    "        width_basis, basis_type, list_shapes, start=0\n",
    "    )\n",
    "    G = perturb([G], 0.01)[0]\n",
    "\n",
    "    if feature_generator is None:\n",
    "        feature_generator = ConstFeatureGen(1)\n",
    "    feature_generator.gen_node_features(G)\n",
    "\n",
    "    name = basis_type + \"_\" + str(width_basis) + \"_\" + str(nb_shapes)  + \"_cycle\"\n",
    "\n",
    "\n",
    "    return G, role_id, name\n",
    "\n",
    "\n",
    "def treegrid(nb_shapes=100, width_basis=4, feature_generator=None, m=4):\n",
    "    \"\"\" Synthetic Graph #5:\n",
    "    Start with a tree and attach grid-shaped subgraphs.\n",
    "    Args:\n",
    "        nb_shapes         :  The number of shapes (here 'houses') that should be added to the base graph.\n",
    "        width_basis       :  The width of the basis graph (here a random 'grid').\n",
    "        feature_generator :  A `FeatureGenerator` for node features. If `None`, add constant features to nodes.\n",
    "        m                 :  The tree depth.\n",
    "    Returns:\n",
    "        G                 :  A networkx graph\n",
    "        role_id           :  Role ID for each node in synthetic graph\n",
    "        name              :  A graph identifier\n",
    "    \"\"\"\n",
    "    basis_type = \"tree\"\n",
    "    list_shapes = [[\"grid\", 6]] * nb_shapes\n",
    "\n",
    "\n",
    "    G, role_id, _ = build_graph(\n",
    "        width_basis, basis_type, list_shapes, start=0\n",
    "    )\n",
    "    G = perturb([G], 0.1)[0]\n",
    "\n",
    "    if feature_generator is None:\n",
    "        feature_generator = ConstFeatureGen(1)\n",
    "    feature_generator.gen_node_features(G)\n",
    "\n",
    "    name = basis_type + \"_\" + str(width_basis) + \"_\" + str(nb_shapes)  + \"_grid\"\n",
    "\n",
    "\n",
    "    return G, role_id, name\n",
    "def treehouse(nb_shapes=100, width_basis=4, feature_generator=None, m=4):\n",
    "    \"\"\" Synthetic Graph #5:\n",
    "    Start with a tree and attach grid-shaped subgraphs.\n",
    "    Args:\n",
    "        nb_shapes         :  The number of shapes (here 'houses') that should be added to the base graph.\n",
    "        width_basis       :  The width of the basis graph (here a random 'grid').\n",
    "        feature_generator :  A `FeatureGenerator` for node features. If `None`, add constant features to nodes.\n",
    "        m                 :  The tree depth.\n",
    "    Returns:\n",
    "        G                 :  A networkx graph\n",
    "        role_id           :  Role ID for each node in synthetic graph\n",
    "        name              :  A graph identifier\n",
    "    \"\"\"\n",
    "    basis_type = \"tree\"\n",
    "    list_shapes = [[\"house\"]] * nb_shapes\n",
    "\n",
    "\n",
    "    G, role_id, _ = build_graph(\n",
    "        width_basis, basis_type, list_shapes, start=0\n",
    "    )\n",
    "    G = perturb([G], 0.1)[0]\n",
    "\n",
    "    if feature_generator is None:\n",
    "        feature_generator = ConstFeatureGen(1)\n",
    "    feature_generator.gen_node_features(G)\n",
    "\n",
    "    name = basis_type + \"_\" + str(width_basis) + \"_\" + str(nb_shapes)  + \"_house\"\n",
    "\n",
    "\n",
    "    return G, role_id, name\n",
    "def treefan(nb_shapes=100, width_basis=4, feature_generator=None, m=4):\n",
    "    \"\"\" Synthetic Graph #5:\n",
    "    Start with a tree and attach grid-shaped subgraphs.\n",
    "    Args:\n",
    "        nb_shapes         :  The number of shapes (here 'houses') that should be added to the base graph.\n",
    "        width_basis       :  The width of the basis graph (here a random 'grid').\n",
    "        feature_generator :  A `FeatureGenerator` for node features. If `None`, add constant features to nodes.\n",
    "        m                 :  The tree depth.\n",
    "    Returns:\n",
    "        G                 :  A networkx graph\n",
    "        role_id           :  Role ID for each node in synthetic graph\n",
    "        name              :  A graph identifier\n",
    "    \"\"\"\n",
    "    basis_type = \"tree\"\n",
    "    list_shapes = [[\"fan\"]] * nb_shapes\n",
    "\n",
    "\n",
    "    G, role_id, _ = build_graph(\n",
    "        width_basis, basis_type, list_shapes, start=0\n",
    "    )\n",
    "    G = perturb([G], 0.1)[0]\n",
    "\n",
    "    if feature_generator is None:\n",
    "        feature_generator = ConstFeatureGen(1)\n",
    "    feature_generator.gen_node_features(G)\n",
    "\n",
    "    name = basis_type + \"_\" + str(width_basis) + \"_\" + str(nb_shapes)  + \"_fan\"\n",
    "\n",
    "\n",
    "    return G, role_id, name\n",
    "def treeclique(nb_shapes=100, width_basis=4, feature_generator=None, m=4):\n",
    "    \"\"\" Synthetic Graph #5:\n",
    "    Start with a tree and attach grid-shaped subgraphs.\n",
    "    Args:\n",
    "        nb_shapes         :  The number of shapes (here 'houses') that should be added to the base graph.\n",
    "        width_basis       :  The width of the basis graph (here a random 'grid').\n",
    "        feature_generator :  A `FeatureGenerator` for node features. If `None`, add constant features to nodes.\n",
    "        m                 :  The tree depth.\n",
    "    Returns:\n",
    "        G                 :  A networkx graph\n",
    "        role_id           :  Role ID for each node in synthetic graph\n",
    "        name              :  A graph identifier\n",
    "    \"\"\"\n",
    "    basis_type = \"tree\"\n",
    "    list_shapes = [[\"clique\"]] * nb_shapes\n",
    "\n",
    "\n",
    "    G, role_id, _ = build_graph(\n",
    "        width_basis, basis_type, list_shapes, start=0\n",
    "    )\n",
    "    G = perturb([G], 0.1)[0]\n",
    "\n",
    "    if feature_generator is None:\n",
    "        feature_generator = ConstFeatureGen(1)\n",
    "    feature_generator.gen_node_features(G)\n",
    "\n",
    "    name = basis_type + \"_\" + str(width_basis) + \"_\" + str(nb_shapes)  + \"_clique\"\n",
    "\n",
    "\n",
    "    return G, role_id, name\n",
    "\n",
    "def treediamond(nb_shapes=100, width_basis=4, feature_generator=None, m=4):\n",
    "    \"\"\" Synthetic Graph #5:\n",
    "    Start with a tree and attach grid-shaped subgraphs.\n",
    "    Args:\n",
    "        nb_shapes         :  The number of shapes (here 'houses') that should be added to the base graph.\n",
    "        width_basis       :  The width of the basis graph (here a random 'grid').\n",
    "        feature_generator :  A `FeatureGenerator` for node features. If `None`, add constant features to nodes.\n",
    "        m                 :  The tree depth.\n",
    "    Returns:\n",
    "        G                 :  A networkx graph\n",
    "        role_id           :  Role ID for each node in synthetic graph\n",
    "        name              :  A graph identifier\n",
    "    \"\"\"\n",
    "    basis_type = \"tree\"\n",
    "    list_shapes = [[\"diamond\"]] * nb_shapes\n",
    "\n",
    "\n",
    "    G, role_id, _ = build_graph(\n",
    "        width_basis, basis_type, list_shapes, start=0\n",
    "    )\n",
    "    G = perturb([G], 0.1)[0]\n",
    "\n",
    "    if feature_generator is None:\n",
    "        feature_generator = ConstFeatureGen(1)\n",
    "    feature_generator.gen_node_features(G)\n",
    "\n",
    "    name = basis_type + \"_\" + str(width_basis) + \"_\" + str(nb_shapes)  + \"_diamond\"\n",
    "\n",
    "\n",
    "    return G, role_id, name\n",
    "\n",
    "def treestar(nb_shapes=100, width_basis=4, feature_generator=None, m=4):\n",
    "    \"\"\" Synthetic Graph #5:\n",
    "    Start with a tree and attach grid-shaped subgraphs.\n",
    "    Args:\n",
    "        nb_shapes         :  The number of shapes (here 'houses') that should be added to the base graph.\n",
    "        width_basis       :  The width of the basis graph (here a random 'grid').\n",
    "        feature_generator :  A `FeatureGenerator` for node features. If `None`, add constant features to nodes.\n",
    "        m                 :  The tree depth.\n",
    "    Returns:\n",
    "        G                 :  A networkx graph\n",
    "        role_id           :  Role ID for each node in synthetic graph\n",
    "        name              :  A graph identifier\n",
    "    \"\"\"\n",
    "    basis_type = \"tree\"\n",
    "    list_shapes = [[\"star\"]] * nb_shapes\n",
    "\n",
    "\n",
    "    G, role_id, _ = build_graph(\n",
    "        width_basis, basis_type, list_shapes, start=0\n",
    "    )\n",
    "    G = perturb([G], 0.1)[0]\n",
    "\n",
    "    if feature_generator is None:\n",
    "        feature_generator = ConstFeatureGen(1)\n",
    "    feature_generator.gen_node_features(G)\n",
    "\n",
    "    name = basis_type + \"_\" + str(width_basis) + \"_\" + str(nb_shapes)  + \"_star\"\n",
    "\n",
    "\n",
    "    return G, role_id, name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = get_from_json(\"../Dataset/features.json\")\n",
    "def syn_motif_ba(feature):\n",
    "    for function in [bahouse,bafan,baclique,badiamond,bacycle,bastar,bagrid]:\n",
    "        for j in range(1,11):\n",
    "            for i in range(1,6):\n",
    "                G_conf,_ ,name = function(nb_shapes=10*i,width_basis=200)\n",
    "                feat = global_feature(G_conf)\n",
    "                #plt.figure(figsize=(8, 6), dpi=300)\n",
    "                #nx.draw(G_conf,nodelist=G_conf.nodes, font_color='white' ,node_size = 50, with_labels=False)\n",
    "                features.append(feat)\n",
    "                name = name+'_'+str(j)\n",
    "                file_name =  \"../Dataset/Motifs_Attached/New_BA/\"+name\n",
    "                nx.write_edgelist(G_conf,file_name+str(\".txt\"))\n",
    "                feature[name] = global_feature(G_conf)\n",
    "    return feature\n",
    "feature = syn_motif_ba(feature)\n",
    "with open(\"../Dataset/features.json\", \"w\") as outfile:\n",
    "    json.dump(feature, outfile, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = get_from_json(\"../Dataset/features.json\")\n",
    "def syn_motif_tree(feature):\n",
    "    for function in [treehouse,treefan,treeclique,treediamond,treecycle,treestar,treegrid]:\n",
    "        for j in range(1,11):\n",
    "            for i in range(1,6):\n",
    "                G_conf,_ ,name = function(nb_shapes=10*i,width_basis=5)\n",
    "                feat = global_feature(G_conf)\n",
    "                #plt.figure(figsize=(8, 6), dpi=300)\n",
    "                #nx.draw(G_conf,nodelist=G_conf.nodes, font_color='white' ,node_size = 50, with_labels=False)\n",
    "                name = name+'_'+str(j)\n",
    "                file_name =  \"../Dataset/Motifs_Attached/New_Tree/\"+name\n",
    "                nx.write_edgelist(G_conf,file_name+str(\".txt\"))\n",
    "                feature[name] = global_feature(G_conf)\n",
    "    return feature\n",
    "feature = syn_motif_tree(feature)\n",
    "with open(\"../Dataset/features.json\", \"w\") as outfile:\n",
    "    json.dump(feature, outfile, cls=NpEncoder)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
